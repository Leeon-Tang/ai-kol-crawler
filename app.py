# -*- coding: utf-8 -*-
"""
å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿ - Streamlit Webç•Œé¢
æ”¯æŒYouTubeã€GitHubç­‰å¤šä¸ªå¹³å°
"""
import streamlit as st
import pandas as pd
import time
import threading
import queue
from datetime import datetime
import json
import os
import sys
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)
os.chdir(PROJECT_ROOT)

# çŠ¶æ€æ–‡ä»¶å’Œæ—¥å¿—ç›®å½•è·¯å¾„
CRAWLER_STATUS_FILE = os.path.join(PROJECT_ROOT, "data", "crawler_status.txt")
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åŠ è½½è‡ªå®šä¹‰CSS
def load_css():
    css_file = os.path.join(PROJECT_ROOT, "static", "style.css")
    if os.path.exists(css_file):
        with open(css_file, 'r', encoding='utf-8') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    else:
        st.warning("CSSæ–‡ä»¶æœªæ‰¾åˆ°")

load_css()

# å…¨å±€æ—¥å¿—é˜Ÿåˆ—
log_queue = queue.Queue()
log_list = []

def add_log(message, level="INFO"):
    """æ·»åŠ æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] [{level}] {message}"
    log_queue.put(log_entry)
    log_list.append(log_entry)
    if len(log_list) > 1000:
        log_list.pop(0)
    
    # å†™å…¥æ–‡ä»¶
    try:
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        log_file = f"{log_dir}/{datetime.now().strftime('%Y%m%d')}.log"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry + "\n")
    except:
        pass

def set_crawler_running(status):
    """è®¾ç½®çˆ¬è™«è¿è¡ŒçŠ¶æ€"""
    try:
        status_dir = os.path.dirname(CRAWLER_STATUS_FILE)
        os.makedirs(status_dir, exist_ok=True)
        with open(CRAWLER_STATUS_FILE, 'w', encoding='utf-8') as f:
            f.write("running" if status else "stopped")
    except:
        pass

def is_crawler_running():
    """è·å–çˆ¬è™«è¿è¡ŒçŠ¶æ€"""
    try:
        if os.path.exists(CRAWLER_STATUS_FILE):
            with open(CRAWLER_STATUS_FILE, 'r', encoding='utf-8') as f:
                status = f.read().strip()
                return status == "running"
    except:
        pass
    return False

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'db' not in st.session_state:
        st.session_state.db = None
    if 'youtube_repository' not in st.session_state:
        st.session_state.youtube_repository = None
    if 'github_repository' not in st.session_state:
        st.session_state.github_repository = None
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "youtube_dashboard"
    if 'jump_to_logs' not in st.session_state:
        st.session_state.jump_to_logs = False
    if 'auto_refresh_enabled' not in st.session_state:
        st.session_state.auto_refresh_enabled = True

def connect_database():
    """è¿æ¥æ•°æ®åº“"""
    try:
        if st.session_state.db is None:
            from storage.database import Database
            from storage.repositories.youtube_repository import YouTubeRepository
            from storage.repositories.github_repository import GitHubRepository
            
            db = Database()
            db.connect()
            db.init_tables()
            
            # å°è¯•è¿ç§»æ—§æ•°æ®
            try:
                from storage.migrations.migration_v2 import MigrationV2
                migration = MigrationV2()
                if migration.check_old_tables_exist():
                    add_log("æ£€æµ‹åˆ°æ—§ç‰ˆæ•°æ®ï¼Œæ­£åœ¨è¿ç§»...", "INFO")
                    migration.migrate()
                    add_log("æ•°æ®è¿ç§»å®Œæˆ", "INFO")
            except Exception as e:
                add_log(f"æ•°æ®è¿ç§»æ£€æŸ¥: {e}", "WARNING")
            
            st.session_state.db = db
            st.session_state.youtube_repository = YouTubeRepository(db)
            st.session_state.github_repository = GitHubRepository(db)
            return True
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        return False
    return True

def get_statistics(platform='youtube'):
    """è·å–ç»Ÿè®¡æ•°æ®"""
    if platform == 'youtube' and st.session_state.youtube_repository:
        try:
            return st.session_state.youtube_repository.get_statistics()
        except:
            return {'total_kols': 0, 'qualified_kols': 0, 'pending_kols': 0, 'total_videos': 0, 'pending_expansions': 0}
    elif platform == 'github' and st.session_state.github_repository:
        try:
            return st.session_state.github_repository.get_statistics()
        except:
            return {'total_developers': 0, 'qualified_developers': 0, 'pending_developers': 0, 'total_repositories': 0}
    return {}

def clear_logs():
    """æ¸…ç©ºæ—¥å¿—"""
    global log_list
    log_list.clear()
    log_file = os.path.join(LOG_DIR, f"{datetime.now().strftime('%Y%m%d')}.log")
    if os.path.exists(log_file):
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write("")
            return True
        except:
            return False
    return True

def run_youtube_crawler_task(task_type, repository, **kwargs):
    """è¿è¡ŒYouTubeçˆ¬è™«ä»»åŠ¡"""
    try:
        from platforms.youtube.scraper import YouTubeScraper
        from platforms.youtube.searcher import KeywordSearcher
        from platforms.youtube.analyzer import KOLAnalyzer
        from platforms.youtube.expander import KOLExpander
        from platforms.youtube.filter import KOLFilter
        from tasks.youtube.discovery import YouTubeDiscoveryTask
        from tasks.youtube.expand import YouTubeExpandTask
        
        set_crawler_running(True)
        add_log(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_type}", "INFO")
        
        scraper = YouTubeScraper()
        searcher = KeywordSearcher(scraper)
        analyzer = KOLAnalyzer(scraper)
        expander = KOLExpander(scraper)
        filter_obj = KOLFilter(repository)
        
        if task_type == "discovery":
            task = YouTubeDiscoveryTask(searcher, analyzer, filter_obj, repository)
            keyword_limit = kwargs.get('keyword_limit', 30)
            add_log(f"ä½¿ç”¨ {keyword_limit} ä¸ªå…³é”®è¯è¿›è¡Œæœç´¢", "INFO")
            task.run(keyword_limit)
        elif task_type == "expand":
            task = YouTubeExpandTask(expander, analyzer, filter_obj, repository)
            add_log("å¼€å§‹æ‰©æ•£ä»»åŠ¡", "INFO")
            task.run()
        
        add_log(f"ä»»åŠ¡å®Œæˆ: {task_type}", "SUCCESS")
    except Exception as e:
        add_log(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        add_log(traceback.format_exc(), "ERROR")
    finally:
        set_crawler_running(False)

def run_github_crawler_task(task_type, repository, **kwargs):
    """è¿è¡ŒGitHubçˆ¬è™«ä»»åŠ¡"""
    try:
        from platforms.github.scraper import GitHubScraper
        from platforms.github.searcher import GitHubSearcher
        from platforms.github.analyzer import GitHubAnalyzer
        from tasks.github.discovery import GitHubDiscoveryTask
        
        set_crawler_running(True)
        add_log(f"å¼€å§‹æ‰§è¡ŒGitHubä»»åŠ¡: {task_type}", "INFO")
        
        scraper = GitHubScraper()
        searcher = GitHubSearcher(scraper, repository)  # ä¼ å…¥repositoryç”¨äºå»é‡
        analyzer = GitHubAnalyzer(scraper)
        
        if task_type == "discovery":
            task = GitHubDiscoveryTask(searcher, analyzer, repository)
            max_developers = kwargs.get('max_developers', 50)
            strategy = kwargs.get('strategy', 'comprehensive')
            task.run(max_developers=max_developers, strategy=strategy)
        
        add_log(f"GitHubä»»åŠ¡å®Œæˆ: {task_type}", "SUCCESS")
    except Exception as e:
        add_log(f"GitHubä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        add_log(traceback.format_exc(), "ERROR")
    finally:
        set_crawler_running(False)



def render_youtube_dashboard():
    """æ¸²æŸ“YouTubeä»ªè¡¨ç›˜"""
    st.markdown('<div class="main-header">ğŸ“Š YouTube æ•°æ®æ¦‚è§ˆ</div>', unsafe_allow_html=True)
    
    stats = get_statistics('youtube')
    
    # ç¬¬ä¸€è¡Œï¼šä¸»è¦æŒ‡æ ‡ï¼ˆå¤§å¡ç‰‡ï¼‰
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"""
        <div class="big-metric-card">
            <div class="metric-label">æ€»KOLæ•°</div>
            <div class="metric-value">{stats.get('total_kols', 0)}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="big-metric-card highlight">
            <div class="metric-label">åˆæ ¼KOL</div>
            <div class="metric-value">{stats.get('qualified_kols', 0)}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="big-metric-card">
            <div class="metric-label">å¾…åˆ†æ</div>
            <div class="metric-value">{stats.get('pending_kols', 0)}</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # ç¬¬äºŒè¡Œï¼šæ¬¡è¦æŒ‡æ ‡ï¼ˆä¸­ç­‰å¡ç‰‡ï¼‰
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"""
        <div class="medium-metric-card">
            <div class="metric-label">æ€»è§†é¢‘æ•°</div>
            <div class="metric-value-medium">{stats.get('total_videos', 0):,}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="medium-metric-card">
            <div class="metric-label">å¾…æ‰©æ•£é˜Ÿåˆ—</div>
            <div class="metric-value-medium">{stats.get('pending_expansions', 0)}</div>
        </div>
        """, unsafe_allow_html=True)

def render_github_dashboard():
    """æ¸²æŸ“GitHubä»ªè¡¨ç›˜"""
    st.markdown('<div class="main-header">ğŸ“Š GitHub æ•°æ®æ¦‚è§ˆ</div>', unsafe_allow_html=True)
    
    stats = get_statistics('github')
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"""
        <div class="big-metric-card">
            <div class="metric-label">æ€»å¼€å‘è€…æ•°</div>
            <div class="metric-value">{stats.get('total_developers', 0)}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="big-metric-card highlight">
            <div class="metric-label">åˆæ ¼å¼€å‘è€…</div>
            <div class="metric-value">{stats.get('qualified_developers', 0)}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="big-metric-card">
            <div class="metric-label">å¾…åˆ†æ</div>
            <div class="metric-value">{stats.get('pending_developers', 0)}</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"""
        <div class="medium-metric-card">
            <div class="metric-label">æ€»ä»“åº“æ•°</div>
            <div class="metric-value-medium">{stats.get('total_repositories', 0):,}</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        qualified = stats.get('qualified_developers', 0)
        total = max(stats.get('total_developers', 1), 1)
        rate = (qualified / total * 100)
        st.markdown(f"""
        <div class="medium-metric-card">
            <div class="metric-label">åˆæ ¼ç‡</div>
            <div class="metric-value-medium">{rate:.1f}%</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        repos = stats.get('total_repositories', 0)
        devs = max(stats.get('total_developers', 1), 1)
        avg = repos / devs
        st.markdown(f"""
        <div class="medium-metric-card">
            <div class="metric-label">å¹³å‡ä»“åº“æ•°</div>
            <div class="metric-value-medium">{avg:.1f}</div>
        </div>
        """, unsafe_allow_html=True)

def render_youtube_crawler():
    """æ¸²æŸ“YouTubeçˆ¬è™«æ§åˆ¶"""
    st.markdown('<div class="main-header">ğŸš€ YouTube çˆ¬è™«æ§åˆ¶</div>', unsafe_allow_html=True)
    
    running = is_crawler_running()
    if running:
        st.warning("âš ï¸ çˆ¬è™«æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        st.info("ğŸ’¡ åˆ‡æ¢åˆ°ã€ŒğŸ“ æ—¥å¿—æŸ¥çœ‹ã€é¡µé¢æŸ¥çœ‹å®æ—¶è¿›åº¦")
        if st.button("â¹ï¸ æ ‡è®°ä¸ºå·²å®Œæˆ", key="mark_complete"):
            set_crawler_running(False)
            st.rerun()
    else:
        st.success("âœ… çˆ¬è™«ç©ºé—²ï¼Œå¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡")
    
    st.divider()
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ” åˆå§‹å‘ç°ä»»åŠ¡")
        st.write("é€šè¿‡å…³é”®è¯æœç´¢YouTubeï¼Œå‘ç°æ–°çš„AI KOL")
        
        keyword_limit = st.slider(
            "ä½¿ç”¨å…³é”®è¯æ•°é‡",
            min_value=1,
            max_value=50,
            value=5,
            step=1,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„å…³é”®è¯æ•°é‡ï¼Œæ•°é‡è¶Šå¤šå‘ç°çš„KOLè¶Šå¤šï¼Œä½†è€—æ—¶ä¹Ÿè¶Šé•¿"
        )
        
        st.info(f"é¢„è®¡æœç´¢ {keyword_limit * 5} ä¸ªé¢‘é“ï¼Œè€—æ—¶çº¦ {keyword_limit * 2} åˆ†é’Ÿ")
        
        if st.button("â–¶ï¸ å¼€å§‹åˆå§‹å‘ç°", disabled=running, key="start_youtube_discovery"):
                if not st.session_state.youtube_repository:
                    st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
                else:
                    clear_logs()
                    add_log("=" * 60, "INFO")
                    add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - YouTubeåˆå§‹å‘ç°", "INFO")
                    add_log("=" * 60, "INFO")
                    add_log(f"ç”¨æˆ·å¯åŠ¨åˆå§‹å‘ç°ä»»åŠ¡ï¼Œå…³é”®è¯æ•°é‡: {keyword_limit}", "INFO")
                    
                    thread = threading.Thread(
                        target=run_youtube_crawler_task,
                        args=("discovery", st.session_state.youtube_repository),
                        kwargs={'keyword_limit': keyword_limit}
                    )
                    thread.daemon = True
                    thread.start()
                    set_crawler_running(True)
                    st.session_state.jump_to_logs = True
                    st.session_state.auto_refresh_enabled = True
                    time.sleep(0.5)
                    st.rerun()
    
    with col2:
        st.subheader("ğŸŒ æ‰©æ•£å‘ç°ä»»åŠ¡")
        st.write("ä»å·²æœ‰KOLçš„æ¨èåˆ—è¡¨ä¸­å‘ç°æ–°KOL")
        
        stats = get_statistics('youtube')
        st.info(f"å½“å‰å¾…æ‰©æ•£é˜Ÿåˆ—: {stats.get('pending_expansions', 0)} ä¸ªKOL")
        
        if stats.get('pending_expansions', 0) == 0:
            st.warning("æ‰©æ•£é˜Ÿåˆ—ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œåˆå§‹å‘ç°ä»»åŠ¡")
        
        if st.button("â–¶ï¸ å¼€å§‹æ‰©æ•£å‘ç°", disabled=running or stats.get('pending_expansions', 0) == 0, key="start_youtube_expand"):
                if not st.session_state.youtube_repository:
                    st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
                else:
                    clear_logs()
                    add_log("=" * 60, "INFO")
                    add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - YouTubeæ‰©æ•£å‘ç°", "INFO")
                    add_log("=" * 60, "INFO")
                    add_log("ç”¨æˆ·å¯åŠ¨æ‰©æ•£å‘ç°ä»»åŠ¡", "INFO")
                    
                    thread = threading.Thread(
                        target=run_youtube_crawler_task,
                        args=("expand", st.session_state.youtube_repository)
                    )
                    thread.daemon = True
                    thread.start()
                    set_crawler_running(True)
                    st.session_state.jump_to_logs = True
                    st.session_state.auto_refresh_enabled = True
                    time.sleep(0.5)
                    st.rerun()
    
    st.divider()
    
    with st.expander("âš™ï¸ é«˜çº§é…ç½®", expanded=False):
        st.subheader("çˆ¬è™«å‚æ•°è®¾ç½®")
        col1, col2 = st.columns(2)
        with col1:
            ai_threshold = st.slider("AIå†…å®¹å æ¯”é˜ˆå€¼", min_value=0.1, max_value=0.9, value=0.3, step=0.05, format="%.0f%%")
            sample_videos = st.number_input("æ¯ä¸ªé¢‘é“åˆ†æè§†é¢‘æ•°", min_value=5, max_value=50, value=10, step=5)
        with col2:
            rate_limit = st.number_input("è¯·æ±‚é—´éš”(ç§’)", min_value=1, max_value=10, value=2, step=1)
            max_kols = st.number_input("æœ€å¤§KOLæ•°é‡", min_value=100, max_value=10000, value=1000, step=100)
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            st.success("é…ç½®å·²ä¿å­˜ï¼")

def render_github_crawler():
    """æ¸²æŸ“GitHubçˆ¬è™«æ§åˆ¶"""
    st.markdown('<div class="main-header">ğŸš€ GitHub çˆ¬è™«æ§åˆ¶</div>', unsafe_allow_html=True)
    
    running = is_crawler_running()
    if running:
        st.warning("âš ï¸ çˆ¬è™«æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        st.info("ğŸ’¡ åˆ‡æ¢åˆ°ã€ŒğŸ“ æ—¥å¿—æŸ¥çœ‹ã€é¡µé¢æŸ¥çœ‹å®æ—¶è¿›åº¦")
        if st.button("â¹ï¸ æ ‡è®°ä¸ºå·²å®Œæˆ", key="mark_complete_github"):
            set_crawler_running(False)
            st.rerun()
    else:
        st.success("âœ… çˆ¬è™«ç©ºé—²ï¼Œå¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡")
    
    st.divider()
    
    st.subheader("ğŸ” GitHubå¼€å‘è€…å‘ç°")
    st.write("ä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼ˆæ— APIé™åˆ¶ï¼‰æœç´¢GitHubï¼Œå‘ç°ç‹¬ç«‹AIå¼€å‘è€…")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        max_developers = st.slider(
            "æœ€å¤§çˆ¬å–å¼€å‘è€…æ•°é‡",
            min_value=1,
            max_value=400,
            value=50,
            step=1,
            help="é™åˆ¶æœ¬æ¬¡ä»»åŠ¡æœ€å¤šçˆ¬å–çš„å¼€å‘è€…æ•°é‡"
        )
    
    with col2:
        strategy = st.selectbox(
            "æœç´¢ç­–ç•¥",
            ["quality_projects", "comprehensive", "keywords", "topics", "awesome", "explore", "indie"],
            index=0,
            format_func=lambda x: {
                "quality_projects": "ğŸ¯ ä¼˜è´¨é¡¹ç›®è´¡çŒ®è€…ï¼ˆæ¨èï¼‰",
                "comprehensive": "ğŸ“¦ ç»¼åˆç­–ç•¥",
                "keywords": "ğŸ”‘ ä»…å…³é”®è¯",
                "topics": "ğŸ·ï¸ ä»…Topics",
                "awesome": "â­ ä»…Awesomeåˆ—è¡¨",
                "explore": "ğŸ”­ ä»…Explore",
                "indie": "ğŸ‘¤ ä»…ç‹¬ç«‹å¼€å‘è€…"
            }[x],
            help="ä¼˜è´¨é¡¹ç›®ç­–ç•¥ï¼šä»Stable Diffusionã€ComfyUIç­‰ä¼˜è´¨AIé¡¹ç›®ä¸­æ‰¾è´¡çŒ®è€…ï¼ˆæœ€ç²¾å‡†ï¼‰"
        )
    
    # ç­–ç•¥è¯´æ˜
    strategy_info = {
        "quality_projects": "ä»Stable Diffusionã€ComfyUIç­‰ä¼˜è´¨AIé¡¹ç›®ï¼ˆ100+ starsï¼‰ä¸­æ‰¾è´¡çŒ®è€…ï¼Œç­›é€‰æœ‰å½±å“åŠ›çš„å¼€å‘è€…ï¼ˆæœ€ç²¾å‡†ï¼Œæ¨èï¼‰",
        "comprehensive": "æ™ºèƒ½ç»„åˆå¤šç§ç­–ç•¥ï¼Œå°æ•°é‡æ—¶åªç”¨æœ€å¿«çš„æ–¹æ³•ï¼Œå¤§æ•°é‡æ—¶å…¨ç­–ç•¥è¦†ç›–",
        "keywords": "é€šè¿‡AIç›¸å…³å…³é”®è¯æœç´¢ä»“åº“ï¼Œæå–ownerï¼ˆå¿«é€Ÿï¼Œé€‚åˆå°æ•°é‡ï¼‰",
        "topics": "é€šè¿‡GitHub Topicsæ ‡ç­¾æœç´¢ï¼ˆä¸­ç­‰é€Ÿåº¦ï¼Œè´¨é‡è¾ƒé«˜ï¼‰",
        "awesome": "ä»Awesomeåˆ—è¡¨æå–è´¡çŒ®è€…ï¼ˆæ…¢ä½†è´¨é‡é«˜ï¼‰",
        "explore": "æœç´¢trendingé¡¹ç›®ï¼ˆè¦†ç›–é¢å¹¿ï¼‰",
        "indie": "ä¸“é—¨æœç´¢ç‹¬ç«‹å¼€å‘è€…å…³é”®è¯ï¼ˆç²¾å‡†ä½†æ•°é‡å°‘ï¼‰"
    }
    
    st.info(f"ğŸ’¡ {strategy_info[strategy]}")
    
    # é¢„ä¼°æ—¶é—´
    if max_developers <= 10:
        estimated_time = "çº¦1-2åˆ†é’Ÿ"
    elif max_developers <= 50:
        estimated_time = "çº¦3-5åˆ†é’Ÿ"
    elif max_developers <= 100:
        estimated_time = "çº¦8-12åˆ†é’Ÿ"
    else:
        estimated_time = "çº¦15-25åˆ†é’Ÿ"
    
    st.caption(f"â±ï¸ é¢„è®¡è€—æ—¶ï¼š{estimated_time}ï¼ˆä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼Œæ— APIé™åˆ¶ï¼‰")
    
    if st.button("â–¶ï¸ å¼€å§‹GitHubå‘ç°", disabled=running, key="start_github_discovery"):
        if not st.session_state.github_repository:
            st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
        else:
            clear_logs()
            add_log("=" * 60, "INFO")
            add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - GitHubå¼€å‘è€…å‘ç°", "INFO")
            add_log("=" * 60, "INFO")
            add_log(f"ç”¨æˆ·å¯åŠ¨GitHubå‘ç°ä»»åŠ¡", "INFO")
            add_log(f"  - æœ€å¤§æ•°é‡: {max_developers}", "INFO")
            add_log(f"  - æœç´¢ç­–ç•¥: {strategy}", "INFO")
            add_log(f"  - ä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼ˆæ— APIé™åˆ¶ï¼‰", "INFO")
            
            thread = threading.Thread(
                target=run_github_crawler_task,
                args=("discovery", st.session_state.github_repository),
                kwargs={"max_developers": max_developers, "strategy": strategy}
            )
            thread.daemon = True
            thread.start()
            set_crawler_running(True)
            st.session_state.jump_to_logs = True
            st.session_state.auto_refresh_enabled = True
            time.sleep(0.5)
            st.rerun()

def render_data_browser():
    """æ¸²æŸ“ç»Ÿä¸€çš„æ•°æ®æµè§ˆé¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“‹ æ•°æ®æµè§ˆ</div>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–å¹³å°é€‰æ‹©
    if 'data_browser_platform' not in st.session_state:
        st.session_state.data_browser_platform = "YouTube"
    
    # å¹³å°é€‰æ‹© - ä½¿ç”¨æŒ‰é’®ç»„
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ¥ YouTube", key="btn_yt_data", use_container_width=True, 
                    type="primary" if st.session_state.data_browser_platform == "YouTube" else "secondary"):
            st.session_state.data_browser_platform = "YouTube"
            st.rerun()
    with col2:
        if st.button("ğŸ’» GitHub", key="btn_gh_data", use_container_width=True,
                    type="primary" if st.session_state.data_browser_platform == "GitHub" else "secondary"):
            st.session_state.data_browser_platform = "GitHub"
            st.rerun()
    
    st.divider()
    
    if st.session_state.data_browser_platform == "YouTube":
        render_youtube_data_content()
    else:
        render_github_data_content()

def render_youtube_data_content():
    """æ¸²æŸ“YouTubeæ•°æ®å†…å®¹"""
    if not st.session_state.youtube_repository:
        st.warning("è¯·å…ˆè¿æ¥æ•°æ®åº“")
        return
    
    col1, col2, col3 = st.columns(3)
    with col1:
        status_filter = st.selectbox("çŠ¶æ€ç­›é€‰", ["å…¨éƒ¨", "åˆæ ¼", "å¾…åˆ†æ", "å·²æ‹’ç»"], index=1, key="yt_status")
    with col2:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["çˆ¬å–æ—¶é—´", "AIå æ¯”", "è®¢é˜…æ•°", "å¹³å‡è§‚çœ‹"], index=0, key="yt_sort")
    with col3:
        limit = st.number_input("æ˜¾ç¤ºæ•°é‡", min_value=10, max_value=1000, value=50, step=10, key="yt_limit")
    
    status_map = {"å…¨éƒ¨": None, "åˆæ ¼": "qualified", "å¾…åˆ†æ": "pending", "å·²æ‹’ç»": "rejected"}
    sort_map = {"çˆ¬å–æ—¶é—´": "discovered_at DESC", "AIå æ¯”": "ai_ratio DESC", "è®¢é˜…æ•°": "subscribers DESC", "å¹³å‡è§‚çœ‹": "avg_views DESC"}
    
    query = "SELECT * FROM youtube_kols"
    if status_filter != "å…¨éƒ¨":
        query += f" WHERE status = '{status_map[status_filter]}'"
    query += f" ORDER BY {sort_map[sort_by]} LIMIT {limit}"
    
    kols = st.session_state.db.fetchall(query)
    
    if kols:
        df = pd.DataFrame(kols)
        display_columns = ['channel_name', 'channel_url', 'subscribers', 'total_videos', 'ai_ratio',
                         'avg_views', 'avg_likes', 'avg_comments', 'engagement_rate', 'contact_info', 'status', 'discovered_at']
        display_df = df[display_columns].copy()
        display_df.columns = ['é¢‘é“åç§°', 'é¢‘é“é“¾æ¥', 'è®¢é˜…æ•°', 'æ€»è§†é¢‘', 'AIå æ¯”', 'å¹³å‡è§‚çœ‹', 'å¹³å‡ç‚¹èµ', 'å¹³å‡è¯„è®º', 'äº’åŠ¨ç‡', 'è”ç³»æ–¹å¼', 'çŠ¶æ€', 'çˆ¬å–æ—¶é—´']
        display_df = df[display_columns].copy()
        display_df.columns = ['é¢‘é“åç§°', 'é¢‘é“é“¾æ¥', 'è®¢é˜…æ•°', 'æ€»è§†é¢‘', 'AIå æ¯”', 'å¹³å‡è§‚çœ‹', 'å¹³å‡ç‚¹èµ', 'å¹³å‡è¯„è®º', 'äº’åŠ¨ç‡', 'è”ç³»æ–¹å¼', 'çŠ¶æ€', 'çˆ¬å–æ—¶é—´']
        
        display_df['æ€»è§†é¢‘'] = display_df['æ€»è§†é¢‘'].apply(lambda x: str(int(x)))
        display_df['AIå æ¯”'] = display_df['AIå æ¯”'].apply(lambda x: f"{x*100:.1f}%")
        display_df['äº’åŠ¨ç‡'] = display_df['äº’åŠ¨ç‡'].apply(lambda x: f"{x:.2f}%")
        display_df['è®¢é˜…æ•°'] = display_df['è®¢é˜…æ•°'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡è§‚çœ‹'] = display_df['å¹³å‡è§‚çœ‹'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡ç‚¹èµ'] = display_df['å¹³å‡ç‚¹èµ'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡è¯„è®º'] = display_df['å¹³å‡è¯„è®º'].apply(lambda x: f"{x:,}")
        display_df['è”ç³»æ–¹å¼'] = display_df['è”ç³»æ–¹å¼'].fillna('')
        
        def format_time(dt):
            if pd.isna(dt):
                return ""
            if isinstance(dt, str):
                dt = pd.to_datetime(dt)
            dt_beijing = dt + pd.Timedelta(hours=8)
            return dt_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        display_df['çˆ¬å–æ—¶é—´'] = display_df['çˆ¬å–æ—¶é—´'].apply(format_time)
        
        table_height = min(max(len(display_df) * 35 + 50, 200), 800)
        st.dataframe(display_df, width='stretch', hide_index=True, height=table_height,
                    column_config={"é¢‘é“é“¾æ¥": st.column_config.LinkColumn("é¢‘é“é“¾æ¥", help="ç‚¹å‡»æ‰“å¼€YouTubeé¢‘é“")})
        
        st.divider()
        
        # å¯¼å‡ºæŒ‰é’® - åˆå¹¶ä¸ºä¸€ä¸ª
        if st.button("ğŸ“¥ å¯¼å‡ºæ•°æ®", key="export_yt_data", use_container_width=True):
            try:
                from tasks.youtube.export import YouTubeExportTask
                export_task = YouTubeExportTask(st.session_state.youtube_repository)
                filepath = export_task.run()
                if filepath and os.path.exists(filepath):
                    with open(filepath, 'rb') as f:
                        excel_data = f.read()
                    st.download_button(
                        label="ğŸ’¾ ä¸‹è½½Excelæ–‡ä»¶",
                        data=excel_data,
                        file_name=os.path.basename(filepath),
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                        key="download_yt_excel_file"
                    )
                    add_log(f"å¯¼å‡ºExcelæˆåŠŸ: {filepath}", "SUCCESS")
            except Exception as e:
                st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
                add_log(f"å¯¼å‡ºExcelå¤±è´¥: {str(e)}", "ERROR")
    else:
        st.info("ğŸ“­ æš‚æ— æ•°æ®")

def render_github_data_content():
    """æ¸²æŸ“GitHubæ•°æ®å†…å®¹"""
    if not st.session_state.github_repository:
        st.warning("è¯·å…ˆè¿æ¥æ•°æ®åº“")
        return
    
    col1, col2, col3 = st.columns(3)
    with col1:
        status_filter = st.selectbox("çŠ¶æ€ç­›é€‰", ["å…¨éƒ¨", "åˆæ ¼", "å¾…åˆ†æ", "å·²æ‹’ç»"], index=1, key="gh_status")
    with col2:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["çˆ¬å–æ—¶é—´", "æ€»Stars", "Followers", "ä»“åº“æ•°"], index=0, key="gh_sort")
    with col3:
        limit = st.number_input("æ˜¾ç¤ºæ•°é‡", min_value=10, max_value=1000, value=50, step=10, key="gh_limit")
    
    status_map = {"å…¨éƒ¨": None, "åˆæ ¼": "qualified", "å¾…åˆ†æ": "pending", "å·²æ‹’ç»": "rejected"}
    sort_map = {"çˆ¬å–æ—¶é—´": "discovered_at DESC", "æ€»Stars": "total_stars DESC", "Followers": "followers DESC", "ä»“åº“æ•°": "public_repos DESC"}
    
    query = "SELECT * FROM github_developers"
    if status_filter != "å…¨éƒ¨":
        query += f" WHERE status = '{status_map[status_filter]}'"
    query += f" ORDER BY {sort_map[sort_by]} LIMIT {limit}"
    
    devs = st.session_state.db.fetchall(query)
    
    if devs:
        df = pd.DataFrame(devs)
        display_columns = ['username', 'name', 'profile_url', 'followers', 'public_repos', 'total_stars', 'contact_info', 'status', 'discovered_at']
        display_df = df[display_columns].copy()
        display_df.columns = ['ç”¨æˆ·å', 'å§“å', 'ä¸»é¡µé“¾æ¥', 'Followers', 'ä»“åº“æ•°', 'æ€»Stars', 'è”ç³»æ–¹å¼', 'çŠ¶æ€', 'çˆ¬å–æ—¶é—´']
        
        display_df['Followers'] = display_df['Followers'].apply(lambda x: f"{x:,}")
        display_df['ä»“åº“æ•°'] = display_df['ä»“åº“æ•°'].apply(lambda x: f"{x:,}")
        display_df['æ€»Stars'] = display_df['æ€»Stars'].apply(lambda x: f"{x:,}")
        display_df['è”ç³»æ–¹å¼'] = display_df['è”ç³»æ–¹å¼'].fillna('')
        
        table_height = min(max(len(display_df) * 35 + 50, 200), 800)
        st.dataframe(display_df, width='stretch', hide_index=True, height=table_height,
                    column_config={"ä¸»é¡µé“¾æ¥": st.column_config.LinkColumn("ä¸»é¡µé“¾æ¥", help="ç‚¹å‡»æ‰“å¼€GitHubä¸»é¡µ")})
        
        st.divider()
        
        # å¯¼å‡ºæŒ‰é’® - åˆå¹¶ä¸ºä¸€ä¸ª
        if st.button("ğŸ“¥ å¯¼å‡ºæ•°æ®", key="export_gh_data", use_container_width=True):
            try:
                from tasks.github.export import GitHubExportTask
                export_task = GitHubExportTask(st.session_state.github_repository)
                filepath = export_task.run()
                if filepath and os.path.exists(filepath):
                    with open(filepath, 'rb') as f:
                        excel_data = f.read()
                    st.download_button(
                        label="ğŸ’¾ ä¸‹è½½Excelæ–‡ä»¶",
                        data=excel_data,
                        file_name=os.path.basename(filepath),
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True,
                        key="download_gh_excel_file"
                    )
                    add_log(f"å¯¼å‡ºExcelæˆåŠŸ: {filepath}", "SUCCESS")
            except Exception as e:
                st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
                add_log(f"å¯¼å‡ºExcelå¤±è´¥: {str(e)}", "ERROR")
    else:
        st.info("ğŸ“­ æš‚æ— æ•°æ®")

def render_logs():
    """æ¸²æŸ“æ—¥å¿—æŸ¥çœ‹é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“ å®æ—¶æ—¥å¿—</div>', unsafe_allow_html=True)
    
    if 'auto_refresh_enabled' not in st.session_state:
        st.session_state.auto_refresh_enabled = True
    
    crawler_is_running = is_crawler_running()
    
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°æ—¥å¿—", key="refresh_logs_btn"):
            st.rerun()
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—", key="clear_logs_btn"):
            if clear_logs():
                st.success("âœ… æ—¥å¿—å·²æ¸…ç©º")
                time.sleep(0.5)
                st.rerun()
            else:
                st.error("âŒ æ¸…ç©ºæ—¥å¿—å¤±è´¥")
    with col3:
        auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (æ¯3ç§’)", value=st.session_state.auto_refresh_enabled,
                                   key="auto_refresh_checkbox_unique", help="çˆ¬è™«è¿è¡Œæ—¶è‡ªåŠ¨åˆ·æ–°æ—¥å¿—")
        if auto_refresh != st.session_state.auto_refresh_enabled:
            st.session_state.auto_refresh_enabled = auto_refresh
    
    st.divider()
    
    log_file = os.path.join(LOG_DIR, f"{datetime.now().strftime('%Y%m%d')}.log")
    all_logs = []
    
    if os.path.exists(log_file):
        try:
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            for encoding in encodings:
                try:
                    with open(log_file, 'r', encoding=encoding) as f:
                        file_logs = f.readlines()
                        all_logs = [line.strip() for line in file_logs if line.strip()]
                    break
                except UnicodeDecodeError:
                    continue
        except Exception as e:
            st.error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
    
    log_count = len(all_logs)
    display_count = min(log_count, 200)
    
    if crawler_is_running:
        st.markdown(f"""
        <div style="background: linear-gradient(90deg, #1e3a8a 0%, #3b82f6 100%); 
                    padding: 15px; border-radius: 10px; margin-bottom: 10px;">
            <div style="display: flex; align-items: center; justify-content: space-between;">
                <div style="display: flex; align-items: center;">
                    <div style="width: 12px; height: 12px; background: #22c55e; 
                                border-radius: 50%; margin-right: 10px;"></div>
                    <span style="color: white; font-size: 18px; font-weight: bold;">
                        ğŸ”„ çˆ¬è™«è¿è¡Œä¸­...
                    </span>
                </div>
                <span style="color: #e0e7ff; font-size: 14px;">
                    å…± {log_count} æ¡æ—¥å¿— | æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡
                </span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div style="background: linear-gradient(90deg, #065f46 0%, #10b981 100%); 
                    padding: 15px; border-radius: 10px; margin-bottom: 10px;">
            <div style="display: flex; align-items: center; justify-content: space-between;">
                <div style="display: flex; align-items: center;">
                    <span style="color: white; font-size: 18px; font-weight: bold;">
                        âœ… çˆ¬è™«å·²åœæ­¢
                    </span>
                </div>
                <span style="color: #d1fae5; font-size: 14px;">
                    å…± {log_count} æ¡æ—¥å¿— | æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡
                </span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    if all_logs:
        logs_text = "\n".join(all_logs[-200:])
        
        log_container_id = f"log_container_{int(time.time() * 1000)}"
        import html
        logs_html = html.escape(logs_text)
        
        st.markdown(f'<div class="log-container" id="{log_container_id}">{logs_html}</div>', unsafe_allow_html=True)
        
        st.markdown(f"""
        <script>
        setTimeout(function() {{
            var container = document.getElementById('{log_container_id}');
            if (container) {{
                container.scrollTop = container.scrollHeight;
            }}
        }}, 100);
        </script>
        """, unsafe_allow_html=True)
    else:
        st.info("æš‚æ— æ—¥å¿—è®°å½•")
    
    if st.session_state.auto_refresh_enabled and crawler_is_running:
        time.sleep(3)
        st.rerun()

def render_ai_rules():
    """æ¸²æŸ“YouTube AIè§„åˆ™é…ç½®é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ¯ YouTube AIè¿‡æ»¤è§„åˆ™</div>', unsafe_allow_html=True)
    
    st.info("ğŸ’¡ é…ç½®AIå†…å®¹è¯†åˆ«è§„åˆ™ï¼Œè°ƒæ•´å…³é”®è¯å’Œç­›é€‰æ¡ä»¶")
    
    config_path = os.path.join(PROJECT_ROOT, 'config', 'config.json')
    config_example_path = os.path.join(PROJECT_ROOT, 'config', 'config.example.json')
    
    if not os.path.exists(config_path):
        if os.path.exists(config_example_path):
            import shutil
            os.makedirs(os.path.dirname(config_path), exist_ok=True)
            shutil.copy(config_example_path, config_path)
            st.success("âœ… å·²è‡ªåŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶")
        else:
            st.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
            return
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        st.error(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    st.subheader("ğŸ“Š åŸºç¡€ç­›é€‰å‚æ•°")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        ai_ratio_percentage = st.slider("AIå æ¯”é˜ˆå€¼", min_value=0, max_value=100,
                                       value=int(config['crawler']['ai_ratio_threshold'] * 100),
                                       step=5, format="%d%%")
        ai_ratio_threshold = ai_ratio_percentage / 100.0
    
    with col2:
        sample_video_count = st.number_input("åˆ†æè§†é¢‘æ•°", min_value=5, max_value=50,
                                            value=config['crawler']['sample_video_count'], step=5)
    
    with col3:
        active_days_threshold = st.number_input("æ´»è·ƒåº¦é˜ˆå€¼(å¤©)", min_value=30, max_value=365,
                                               value=config['crawler']['active_days_threshold'], step=30)
    
    st.divider()
    
    st.subheader("ğŸ”‘ AIå…³é”®è¯åº“")
    tab1, tab2, tab3 = st.tabs(["ğŸ”¥ é«˜ä¼˜å…ˆçº§", "â­ ä¸­ä¼˜å…ˆçº§", "ğŸ“Œ ä½ä¼˜å…ˆçº§"])
    
    with tab1:
        high_keywords = st.text_area("é«˜ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                                    value="\n".join(config['keywords']['priority_high']),
                                    height=200)
    
    with tab2:
        medium_keywords = st.text_area("ä¸­ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                                      value="\n".join(config['keywords']['priority_medium']),
                                      height=200)
    
    with tab3:
        low_keywords = st.text_area("ä½ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                                   value="\n".join(config['keywords']['priority_low']),
                                   height=200)
    
    st.divider()
    
    st.subheader("ğŸš« æ’é™¤è§„åˆ™")
    all_exclusion_keywords = []
    all_exclusion_keywords.extend(config['exclusion_rules'].get('course_keywords', []))
    all_exclusion_keywords.extend(config['exclusion_rules'].get('academic_keywords', []))
    all_exclusion_keywords.extend(config['exclusion_rules'].get('news_keywords', []))
    
    exclusion_keywords = st.text_area("æ’é™¤å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", value="\n".join(all_exclusion_keywords),
                                     height=200)
    
    if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
        config['crawler']['ai_ratio_threshold'] = ai_ratio_threshold
        config['crawler']['sample_video_count'] = sample_video_count
        config['crawler']['active_days_threshold'] = active_days_threshold
        
        config['keywords']['priority_high'] = [k.strip() for k in high_keywords.split('\n') if k.strip()]
        config['keywords']['priority_medium'] = [k.strip() for k in medium_keywords.split('\n') if k.strip()]
        config['keywords']['priority_low'] = [k.strip() for k in low_keywords.split('\n') if k.strip()]
        
        exclusion_list = [k.strip() for k in exclusion_keywords.split('\n') if k.strip()]
        config['exclusion_rules']['course_keywords'] = exclusion_list
        config['exclusion_rules']['academic_keywords'] = []
        config['exclusion_rules']['news_keywords'] = []
        
        try:
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            st.success("âœ… é…ç½®å·²ä¿å­˜ï¼")
            add_log("YouTube AIè§„åˆ™é…ç½®å·²æ›´æ–°", "INFO")
        except Exception as e:
            st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def render_github_rules():
    """æ¸²æŸ“GitHubè§„åˆ™é…ç½®é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ¯ GitHub ç­›é€‰è§„åˆ™</div>', unsafe_allow_html=True)
    
    st.info("ğŸ’¡ é…ç½®GitHubç‹¬ç«‹å¼€å‘è€…ç­›é€‰è§„åˆ™")
    
    config_path = os.path.join(PROJECT_ROOT, 'config', 'config.json')
    
    if not os.path.exists(config_path):
        st.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        st.error(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # å¦‚æœé…ç½®ä¸­æ²¡æœ‰githubéƒ¨åˆ†ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
    if 'github' not in config:
        config['github'] = {
            'min_followers': 100,
            'min_stars': 500,
            'min_repos': 3,
            'keywords': ['AI', 'machine learning', 'deep learning', 'stable diffusion', 'LLM', 'GPT'],
            'exclusion_companies': [
                'Google', 'Microsoft', 'Meta', 'Facebook', 'Amazon', 'Apple',
                'Alibaba', 'Tencent', 'ByteDance', 'Baidu', 'Huawei', 'OpenAI',
                'Stability AI', 'Midjourney', 'Runway', 'Anthropic', 'Cohere',
                'AWS', 'Azure', 'GCP', 'Cloudflare', 'Vercel'
            ],
            'exclusion_projects': ['ComfyUI', 'Automatic1111', 'Stable Diffusion WebUI', 'LangChain']
        }
    
    st.subheader("ğŸ“Š ç‹¬ç«‹å¼€å‘è€…åˆ¤æ–­æ ‡å‡†")
    
    with st.expander("â„¹ï¸ ä»€ä¹ˆæ˜¯ç‹¬ç«‹å¼€å‘è€…ï¼Ÿ", expanded=True):
        st.markdown("""
        **ç‹¬ç«‹å¼€å‘è€…å¿…é¡»åŒæ—¶æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š**
        
        1. **ä¸å±äºå¤§å…¬å¸** - ä¸åœ¨Googleã€Microsoftã€Metaç­‰å¤§å…¬å¸å·¥ä½œ
        2. **ä¸æ˜¯é¡¹ç›®æˆå‘˜** - ä¸æ˜¯ComfyUIã€Automatic1111ç­‰çŸ¥åé¡¹ç›®çš„å›¢é˜Ÿæˆå‘˜
        3. **æœ‰åŸåˆ›é¡¹ç›®** - è‡³å°‘æœ‰3ä¸ªéforkçš„åŸåˆ›ä»“åº“
        4. **æœ‰å½±å“åŠ›** - Followers â‰¥ 100 æˆ– æ€»Stars â‰¥ 500
        5. **æœ‰AIé¡¹ç›®** - è‡³å°‘æœ‰1ä¸ªAIç›¸å…³çš„åŸåˆ›é¡¹ç›®
        6. **ä¸»è¦æ˜¯åˆ›ä½œè€…** - forké¡¹ç›®çš„starså æ¯”ä¸è¶…è¿‡70%ï¼ˆé¿å…çº¯è´¡çŒ®è€…ï¼‰
        
        **æ’é™¤è§„åˆ™ï¼š**
        - Bioæˆ–Companyä¸­æ ‡æ³¨ä¸ºæŸé¡¹ç›®æˆå‘˜ï¼ˆå¦‚"ComfyUI team member"ï¼‰
        - ä¸»è¦è´¡çŒ®é›†ä¸­åœ¨forkçš„é¡¹ç›®ä¸Š
        """)
    
    st.divider()
    
    st.subheader("ğŸ¯ ç­›é€‰å‚æ•°")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        min_followers = st.number_input(
            "æœ€å°Followersæ•°", 
            min_value=0, max_value=10000,
            value=config['github'].get('min_followers', 100), 
            step=50,
            help="å¼€å‘è€…çš„æœ€å°ç²‰ä¸æ•°é‡"
        )
    
    with col2:
        min_stars = st.number_input(
            "æœ€å°æ€»Starsæ•°", 
            min_value=0, max_value=50000,
            value=config['github'].get('min_stars', 500), 
            step=100,
            help="æ‰€æœ‰åŸåˆ›ä»“åº“çš„æ€»starsæ•°"
        )
    
    with col3:
        min_repos = st.number_input(
            "æœ€å°åŸåˆ›ä»“åº“æ•°", 
            min_value=1, max_value=100,
            value=config['github'].get('min_repos', 3), 
            step=1,
            help="éforkçš„åŸåˆ›ä»“åº“æ•°é‡"
        )
    
    st.divider()
    
    st.subheader("ğŸ”‘ AIç›¸å…³å…³é”®è¯")
    st.caption("ç”¨äºæœç´¢å’Œè¯†åˆ«AIç›¸å…³é¡¹ç›®çš„å…³é”®è¯")
    
    github_keywords = st.text_area(
        "å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        value="\n".join(config['github'].get('keywords', [])),
        height=150,
        help="è¿™äº›å…³é”®è¯ç”¨äºæœç´¢GitHubä»“åº“å’Œåˆ¤æ–­é¡¹ç›®æ˜¯å¦ä¸AIç›¸å…³"
    )
    
    st.divider()
    
    st.subheader("ğŸ¢ æ’é™¤çš„å…¬å¸/ç»„ç»‡")
    st.caption("åœ¨è¿™äº›å…¬å¸å·¥ä½œçš„å¼€å‘è€…å°†è¢«æ’é™¤")
    
    exclusion_companies = st.text_area(
        "å…¬å¸åç§°ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        value="\n".join(config['github'].get('exclusion_companies', [])),
        height=200,
        help="Companyå­—æ®µåŒ…å«è¿™äº›åç§°çš„å¼€å‘è€…å°†è¢«è¿‡æ»¤"
    )
    
    st.divider()
    
    st.subheader("ğŸš« æ’é™¤çš„é¡¹ç›®å›¢é˜Ÿ")
    st.caption("è¿™äº›é¡¹ç›®çš„å›¢é˜Ÿæˆå‘˜å°†è¢«æ’é™¤")
    
    exclusion_projects = st.text_area(
        "é¡¹ç›®åç§°ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        value="\n".join(config['github'].get('exclusion_projects', [])),
        height=150,
        help="Bioæˆ–Companyä¸­æ ‡æ³¨ä¸ºè¿™äº›é¡¹ç›®æˆå‘˜çš„å¼€å‘è€…å°†è¢«è¿‡æ»¤"
    )
    
    st.divider()
    
    if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
        config['github']['min_followers'] = min_followers
        config['github']['min_stars'] = min_stars
        config['github']['min_repos'] = min_repos
        config['github']['keywords'] = [k.strip() for k in github_keywords.split('\n') if k.strip()]
        config['github']['exclusion_companies'] = [k.strip() for k in exclusion_companies.split('\n') if k.strip()]
        config['github']['exclusion_projects'] = [k.strip() for k in exclusion_projects.split('\n') if k.strip()]
        
        try:
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            st.success("âœ… é…ç½®å·²ä¿å­˜ï¼æ–°é…ç½®å°†åœ¨ä¸‹æ¬¡çˆ¬è™«ä»»åŠ¡æ—¶ç”Ÿæ•ˆ")
            add_log("GitHubç­›é€‰è§„åˆ™é…ç½®å·²æ›´æ–°", "INFO")
        except Exception as e:
            st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def render_settings():
    """æ¸²æŸ“è®¾ç½®é¡µé¢"""
    st.markdown('<div class="main-header">âš™ï¸ ç³»ç»Ÿè®¾ç½®</div>', unsafe_allow_html=True)
    
    st.subheader("ğŸ—„ï¸ æ•°æ®åº“ä¿¡æ¯")
    st.info("ğŸ’¡ å½“å‰ä½¿ç”¨SQLiteæ•°æ®åº“ï¼Œæ•°æ®ä¿å­˜åœ¨ data/ai_kol_crawler.db")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š æŸ¥çœ‹æ•°æ®åº“å¤§å°", use_container_width=True):
            db_path = 'data/ai_kol_crawler.db'
            if os.path.exists(db_path):
                size = os.path.getsize(db_path) / 1024 / 1024
                st.info(f"æ•°æ®åº“å¤§å°: {size:.2f} MB")
            else:
                st.warning("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
    
    with col2:
        if st.button("ğŸ’¾ å¤‡ä»½æ•°æ®åº“", use_container_width=True):
            import shutil
            try:
                backup_dir = "backups"
                os.makedirs(backup_dir, exist_ok=True)
                backup_name = f"{backup_dir}/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
                shutil.copy('data/ai_kol_crawler.db', backup_name)
                st.success(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_name}")
            except Exception as e:
                st.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
    
    with col3:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®åº“", use_container_width=True):
            st.warning("âš ï¸ æ­¤æ“ä½œå°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œæ— æ³•æ¢å¤ï¼")
    
    st.divider()
    
    st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ç‰ˆæœ¬ä¿¡æ¯**")
        st.write("- ç³»ç»Ÿç‰ˆæœ¬: v2.0")
        st.write("- æ•°æ®åº“: SQLite")
        st.write("- Python:", sys.version.split()[0])
    
    with col2:
        st.write("**ç»Ÿè®¡ä¿¡æ¯**")
        youtube_stats = get_statistics('youtube')
        github_stats = get_statistics('github')
        st.write(f"- YouTube KOL: {youtube_stats.get('qualified_kols', 0)}")
        st.write(f"- GitHubå¼€å‘è€…: {github_stats.get('qualified_developers', 0)}")


if __name__ == "__main__":
    """ä¸»ç¨‹åº"""
    init_session_state()
    
    with st.sidebar:
        st.markdown("### ğŸ¤– å¤šå¹³å°çˆ¬è™«")
        
        if connect_database():
            st.success("âœ… å·²è¿æ¥")
        else:
            st.error("âŒ æœªè¿æ¥")
        
        # å¿«é€Ÿç»Ÿè®¡ - æ›´ç´§å‡‘
        youtube_stats = get_statistics('youtube')
        github_stats = get_statistics('github')
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ğŸ¥ YouTube**")
            st.markdown(f"<div class='stat-number'>{youtube_stats.get('qualified_kols', 0)}</div>", unsafe_allow_html=True)
        with col2:
            st.markdown("**ğŸ’» GitHub**")
            st.markdown(f"<div class='stat-number'>{github_stats.get('qualified_developers', 0)}</div>", unsafe_allow_html=True)
        
        st.divider()
        
        # æ•°æ®æµè§ˆï¼ˆæœ€å‰é¢ï¼‰
        is_active = st.session_state.current_page == "data_browser"
        if st.button(
            "ğŸ“Š æ•°æ®æµè§ˆ", 
            key="btn_data_browser", 
            use_container_width=True,
            type="primary" if is_active else "secondary"
        ):
            st.session_state.current_page = "data_browser"
            st.rerun()
        
        # YouTubeåˆ†ç±»
        st.markdown("### ğŸ¥ YouTube")
        youtube_pages = {
            "youtube_dashboard": "ğŸ“Š ä»ªè¡¨ç›˜",
            "youtube_crawler": "ğŸš€ çˆ¬è™«",
            "youtube_ai_rules": "ğŸ¯ è§„åˆ™"
        }
        
        for page_key, page_name in youtube_pages.items():
            is_active = st.session_state.current_page == page_key
            if st.button(
                page_name, 
                key=f"btn_{page_key}", 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_page = page_key
                st.rerun()
        
        # GitHubåˆ†ç±»
        st.markdown("### ğŸ’» GitHub")
        github_pages = {
            "github_dashboard": "ğŸ“Š ä»ªè¡¨ç›˜",
            "github_crawler": "ğŸš€ çˆ¬è™«",
            "github_rules": "ğŸ¯ è§„åˆ™"
        }
        
        for page_key, page_name in github_pages.items():
            is_active = st.session_state.current_page == page_key
            if st.button(
                page_name, 
                key=f"btn_{page_key}", 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_page = page_key
                st.rerun()
        
        st.divider()
        
        # æ—¥å¿—æŸ¥çœ‹å’Œè®¾ç½®ï¼ˆæœ€åé¢ï¼‰
        system_pages = {
            "logs": "ğŸ“ æ—¥å¿—æŸ¥çœ‹",
            "settings": "âš™ï¸ è®¾ç½®"
        }
        
        for page_key, page_name in system_pages.items():
            is_active = st.session_state.current_page == page_key
            if st.button(
                page_name, 
                key=f"btn_{page_key}", 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_page = page_key
                st.rerun()
        
        st.divider()
        
        if is_crawler_running():
            st.warning("âš™ï¸ çˆ¬è™«è¿è¡Œä¸­...")
        
        st.caption("å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿ v2.0")
        st.caption("Â© 2026 All Rights Reserved")
    
    # å¤„ç†è·³è½¬åˆ°æ—¥å¿—
    if st.session_state.jump_to_logs:
        st.session_state.current_page = "logs"
        st.session_state.jump_to_logs = False
    
    # ä¸»å†…å®¹åŒº
    page = st.session_state.current_page
    
    if page == "youtube_dashboard":
        render_youtube_dashboard()
    elif page == "youtube_crawler":
        render_youtube_crawler()
    elif page == "youtube_ai_rules":
        render_ai_rules()
    elif page == "github_dashboard":
        render_github_dashboard()
    elif page == "github_crawler":
        render_github_crawler()
    elif page == "github_rules":
        render_github_rules()
    elif page == "data_browser":
        render_data_browser()
    elif page == "logs":
        render_logs()
    elif page == "settings":
        render_settings()
    else:
        render_youtube_dashboard()
