# -*- coding: utf-8 -*-
"""
AI KOLçˆ¬è™«ç³»ç»Ÿ - Streamlitå¯è§†åŒ–ç•Œé¢
"""
import streamlit as st
import pandas as pd
import time
import threading
import queue
from datetime import datetime
import json
import os
import sys
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)

# ç¡®ä¿å·¥ä½œç›®å½•æ˜¯é¡¹ç›®æ ¹ç›®å½•
os.chdir(PROJECT_ROOT)

# çŠ¶æ€æ–‡ä»¶å’Œæ—¥å¿—ç›®å½•è·¯å¾„
CRAWLER_STATUS_FILE = os.path.join(PROJECT_ROOT, "data", "crawler_status.txt")
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶å‡ºé”™
def lazy_import():
    """å»¶è¿Ÿå¯¼å…¥æ¨¡å—"""
    try:
        from storage.database import Database
        from storage.kol_repository import KOLRepository
        from core.scraper import YouTubeScraper
        from core.searcher import KeywordSearcher
        from core.analyzer import KOLAnalyzer
        from core.expander import KOLExpander
        from core.filter import KOLFilter
        from tasks.discovery_task import DiscoveryTask
        from tasks.expand_task import ExpandTask
        from tasks.export_task import ExportTask
        return True
    except Exception as e:
        st.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}")
        st.error(traceback.format_exc())
        return False


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI KOLçˆ¬è™«ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        text-align: center;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
        font-weight: bold;
        border-radius: 5px;
        padding: 0.5rem 1rem;
    }
    .stButton>button:hover {
        background-color: #155a8a;
    }
</style>
""", unsafe_allow_html=True)


# å…¨å±€æ—¥å¿—é˜Ÿåˆ—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
log_queue = queue.Queue()
log_list = []

def set_crawler_running(status):
    """è®¾ç½®çˆ¬è™«è¿è¡ŒçŠ¶æ€ï¼ˆä½¿ç”¨æ–‡ä»¶æ ‡è®°ï¼‰"""
    try:
        status_dir = os.path.dirname(CRAWLER_STATUS_FILE)
        os.makedirs(status_dir, exist_ok=True)
        with open(CRAWLER_STATUS_FILE, 'w', encoding='utf-8') as f:
            f.write("running" if status else "stopped")
    except Exception as e:
        pass

def is_crawler_running():
    """è·å–çˆ¬è™«è¿è¡ŒçŠ¶æ€ï¼ˆä»æ–‡ä»¶è¯»å–ï¼‰"""
    try:
        if os.path.exists(CRAWLER_STATUS_FILE):
            with open(CRAWLER_STATUS_FILE, 'r', encoding='utf-8') as f:
                status = f.read().strip()
                return status == "running"
    except Exception as e:
        pass
    return False

# åˆå§‹åŒ–Session State
def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'db' not in st.session_state:
        st.session_state.db = None
    if 'repository' not in st.session_state:
        st.session_state.repository = None


def connect_database():
    """è¿æ¥æ•°æ®åº“"""
    try:
        if st.session_state.db is None:
            from storage.database import Database
            from storage.kol_repository import KOLRepository
            
            # é»˜è®¤ä½¿ç”¨SQLiteï¼ˆæ— éœ€Dockerï¼‰
            db = Database(use_sqlite=True)
            db.connect()
            db.init_tables()
            st.session_state.db = db
            st.session_state.repository = KOLRepository(db)
            return True
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        st.info("ğŸ’¡ æç¤º: ç¨‹åºä½¿ç”¨SQLiteæ•°æ®åº“ï¼Œæ•°æ®ä¿å­˜åœ¨ data/ai_kol_crawler.db")
        return False
    return True


def get_statistics():
    """è·å–ç»Ÿè®¡æ•°æ®"""
    if st.session_state.repository:
        try:
            return st.session_state.repository.get_statistics()
        except Exception as e:
            add_log(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}", "ERROR")
            return {
                'total_kols': 0,
                'qualified_kols': 0,
                'pending_kols': 0,
                'total_videos': 0,
                'pending_expansions': 0
            }
    return {
        'total_kols': 0,
        'qualified_kols': 0,
        'pending_kols': 0,
        'total_videos': 0,
        'pending_expansions': 0
    }


def add_log(message, level="INFO"):
    """æ·»åŠ æ—¥å¿—ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰- åŒæ—¶å†™å…¥å†…å­˜å’Œæ–‡ä»¶"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] [{level}] {message}"
    
    # æ·»åŠ åˆ°å†…å­˜é˜Ÿåˆ—
    log_queue.put(log_entry)
    log_list.append(log_entry)
    
    # åªä¿ç•™æœ€è¿‘1000æ¡æ—¥å¿—
    if len(log_list) > 1000:
        log_list.pop(0)
    
    # åŒæ—¶å†™å…¥æ—¥å¿—æ–‡ä»¶
    try:
        import os
        log_dir = "logs"
        if not os.path.exists(log_dir):
            os.makedirs(log_dir)
        
        log_file = f"{log_dir}/{datetime.now().strftime('%Y%m%d')}.log"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry + "\n")
    except Exception as e:
        # å†™å…¥æ–‡ä»¶å¤±è´¥ä¸å½±å“ç¨‹åºè¿è¡Œ
        pass


def run_crawler_task(task_type, repository, **kwargs):
    """åœ¨åå°çº¿ç¨‹è¿è¡Œçˆ¬è™«ä»»åŠ¡"""
    try:
        from core.scraper import YouTubeScraper
        from core.searcher import KeywordSearcher
        from core.analyzer import KOLAnalyzer
        from core.expander import KOLExpander
        from core.filter import KOLFilter
        from tasks.discovery_task import DiscoveryTask
        from tasks.expand_task import ExpandTask
        
        set_crawler_running(True)
        add_log(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_type}", "INFO")
        
        # åˆå§‹åŒ–ç»„ä»¶
        scraper = YouTubeScraper()
        searcher = KeywordSearcher(scraper)
        analyzer = KOLAnalyzer(scraper)
        expander = KOLExpander(scraper)
        filter_obj = KOLFilter(repository)
        
        if task_type == "discovery":
            task = DiscoveryTask(searcher, analyzer, filter_obj, repository)
            keyword_limit = kwargs.get('keyword_limit', 30)
            add_log(f"ä½¿ç”¨ {keyword_limit} ä¸ªå…³é”®è¯è¿›è¡Œæœç´¢", "INFO")
            task.run(keyword_limit)
            
        elif task_type == "expand":
            task = ExpandTask(expander, analyzer, filter_obj, repository)
            add_log("å¼€å§‹æ‰©æ•£ä»»åŠ¡", "INFO")
            task.run()
            
        add_log(f"ä»»åŠ¡å®Œæˆ: {task_type}", "SUCCESS")
        
    except Exception as e:
        add_log(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        import traceback
        add_log(traceback.format_exc(), "ERROR")
    finally:
        set_crawler_running(False)


# ==================== é¡µé¢ç»„ä»¶ ====================

def render_dashboard():
    """æ¸²æŸ“ä»ªè¡¨ç›˜é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“Š æ•°æ®ä»ªè¡¨ç›˜</div>', unsafe_allow_html=True)
    
    # è·å–ç»Ÿè®¡æ•°æ®
    stats = get_statistics()
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric(
            label="æ€»KOLæ•°",
            value=stats['total_kols'],
            delta=None
        )
    
    with col2:
        st.metric(
            label="åˆæ ¼KOL",
            value=stats['qualified_kols'],
            delta=None
        )
    
    with col3:
        st.metric(
            label="å¾…åˆ†æ",
            value=stats['pending_kols'],
            delta=None
        )
    
    with col4:
        st.metric(
            label="æ€»è§†é¢‘æ•°",
            value=stats['total_videos'],
            delta=None
        )
    
    with col5:
        st.metric(
            label="å¾…æ‰©æ•£",
            value=stats['pending_expansions'],
            delta=None
        )
    
    st.divider()
    
    # æ˜¾ç¤ºæœ€è¿‘å‘ç°çš„KOL
    st.subheader("ğŸŒŸ æœ€è¿‘å‘ç°çš„åˆæ ¼KOL")
    
    if st.session_state.repository:
        recent_kols = st.session_state.repository.get_qualified_kols(limit=10)
        
        if recent_kols:
            df = pd.DataFrame(recent_kols)
            display_df = df[[
                'channel_name', 'subscribers', 'ai_ratio', 
                'avg_views', 'engagement_rate', 'discovered_at'
            ]].copy()
            
            display_df.columns = ['é¢‘é“åç§°', 'è®¢é˜…æ•°', 'AIå æ¯”', 'å¹³å‡è§‚çœ‹', 'äº’åŠ¨ç‡', 'å‘ç°æ—¶é—´']
            display_df['AIå æ¯”'] = display_df['AIå æ¯”'].apply(lambda x: f"{x*100:.1f}%")
            display_df['äº’åŠ¨ç‡'] = display_df['äº’åŠ¨ç‡'].apply(lambda x: f"{x:.2f}%")
            display_df['è®¢é˜…æ•°'] = display_df['è®¢é˜…æ•°'].apply(lambda x: f"{x:,}")
            display_df['å¹³å‡è§‚çœ‹'] = display_df['å¹³å‡è§‚çœ‹'].apply(lambda x: f"{x:,}")
            
            st.dataframe(display_df, width='stretch', hide_index=True)
        else:
            st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«ä»»åŠ¡")
    
    # åˆ·æ–°æŒ‰é’®
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", key="refresh_dashboard"):
        st.rerun()


def render_crawler_control():
    """æ¸²æŸ“çˆ¬è™«æ§åˆ¶é¡µé¢"""
    st.markdown('<div class="main-header">ğŸš€ çˆ¬è™«æ§åˆ¶ä¸­å¿ƒ</div>', unsafe_allow_html=True)
    
    # æ˜¾ç¤ºè¿è¡ŒçŠ¶æ€
    running = is_crawler_running()
    if running:
        st.warning("âš ï¸ çˆ¬è™«æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        st.info("ğŸ’¡ åˆ‡æ¢åˆ°ã€ŒğŸ“ æ—¥å¿—æŸ¥çœ‹ã€é¡µé¢æŸ¥çœ‹å®æ—¶è¿›åº¦")
        
        # æ·»åŠ åœæ­¢æŒ‰é’®
        if st.button("â¹ï¸ æ ‡è®°ä¸ºå·²å®Œæˆ", key="mark_complete"):
            set_crawler_running(False)
            st.rerun()
    else:
        st.success("âœ… çˆ¬è™«ç©ºé—²ï¼Œå¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡")
    
    st.divider()
    
    # ä»»åŠ¡é€‰æ‹©
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ” åˆå§‹å‘ç°ä»»åŠ¡")
        st.write("é€šè¿‡å…³é”®è¯æœç´¢YouTubeï¼Œå‘ç°æ–°çš„AI KOL")
        
        keyword_limit = st.slider(
            "ä½¿ç”¨å…³é”®è¯æ•°é‡",
            min_value=1,
            max_value=50,
            value=5,
            step=1,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„å…³é”®è¯æ•°é‡ï¼Œæ•°é‡è¶Šå¤šå‘ç°çš„KOLè¶Šå¤šï¼Œä½†è€—æ—¶ä¹Ÿè¶Šé•¿"
        )
        
        st.info(f"é¢„è®¡æœç´¢ {keyword_limit * 5} ä¸ªè§†é¢‘ï¼Œè€—æ—¶çº¦ {keyword_limit * 2} åˆ†é’Ÿ")
        
        if st.button(
            "â–¶ï¸ å¼€å§‹åˆå§‹å‘ç°",
            disabled=running,
            key="start_discovery"
        ):
            if not st.session_state.repository:
                st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
            else:
                # å®Œå…¨æ¸…ç©ºæ—¥å¿—ï¼ˆå†…å­˜å’Œæ–‡ä»¶ï¼‰
                clear_logs()
                
                # æ·»åŠ æ–°ä»»åŠ¡çš„å¼€å§‹æ—¥å¿—
                add_log("=" * 60, "INFO")
                add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - åˆå§‹å‘ç°", "INFO")
                add_log("=" * 60, "INFO")
                add_log(f"ç”¨æˆ·å¯åŠ¨åˆå§‹å‘ç°ä»»åŠ¡ï¼Œå…³é”®è¯æ•°é‡: {keyword_limit}", "INFO")
                
                thread = threading.Thread(
                    target=run_crawler_task,
                    args=("discovery", st.session_state.repository),
                    kwargs={'keyword_limit': keyword_limit}
                )
                thread.daemon = True
                thread.start()
                set_crawler_running(True)
                
                # è®¾ç½®è·³è½¬æ ‡è®°
                st.session_state.jump_to_logs = True
                st.session_state.auto_refresh_enabled = True  # ç¡®ä¿è‡ªåŠ¨åˆ·æ–°å¼€å¯
                time.sleep(0.5)
                st.rerun()
    
    with col2:
        st.subheader("ğŸŒ æ‰©æ•£å‘ç°ä»»åŠ¡")
        st.write("ä»å·²æœ‰KOLçš„æ¨èåˆ—è¡¨ä¸­å‘ç°æ–°KOL")
        
        stats = get_statistics()
        st.info(f"å½“å‰å¾…æ‰©æ•£é˜Ÿåˆ—: {stats['pending_expansions']} ä¸ªKOL")
        
        if stats['pending_expansions'] == 0:
            st.warning("æ‰©æ•£é˜Ÿåˆ—ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œåˆå§‹å‘ç°ä»»åŠ¡")
        
        if st.button(
            "â–¶ï¸ å¼€å§‹æ‰©æ•£å‘ç°",
            disabled=running or stats['pending_expansions'] == 0,
            key="start_expand"
        ):
            if not st.session_state.repository:
                st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
            else:
                # å®Œå…¨æ¸…ç©ºæ—¥å¿—ï¼ˆå†…å­˜å’Œæ–‡ä»¶ï¼‰
                clear_logs()
                
                # æ·»åŠ æ–°ä»»åŠ¡çš„å¼€å§‹æ—¥å¿—
                add_log("=" * 60, "INFO")
                add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - æ‰©æ•£å‘ç°", "INFO")
                add_log("=" * 60, "INFO")
                add_log("ç”¨æˆ·å¯åŠ¨æ‰©æ•£å‘ç°ä»»åŠ¡", "INFO")
                
                thread = threading.Thread(
                    target=run_crawler_task,
                    args=("expand", st.session_state.repository)
                )
                thread.daemon = True
                thread.start()
                set_crawler_running(True)
                # è®¾ç½®è·³è½¬æ ‡è®°
                st.session_state.jump_to_logs = True
                st.session_state.auto_refresh_enabled = True  # ç¡®ä¿è‡ªåŠ¨åˆ·æ–°å¼€å¯
                time.sleep(0.5)
                st.rerun()
    
    st.divider()
    
    # é…ç½®å‚æ•°
    with st.expander("âš™ï¸ é«˜çº§é…ç½®", expanded=False):
        st.subheader("çˆ¬è™«å‚æ•°è®¾ç½®")
        
        col1, col2 = st.columns(2)
        
        with col1:
            ai_threshold = st.slider(
                "AIå†…å®¹å æ¯”é˜ˆå€¼",
                min_value=0.1,
                max_value=0.9,
                value=0.3,
                step=0.05,
                format="%.0f%%",
                help="åªæœ‰AIå†…å®¹å æ¯”è¶…è¿‡æ­¤é˜ˆå€¼çš„é¢‘é“æ‰ä¼šè¢«æ ‡è®°ä¸ºåˆæ ¼"
            )
            
            sample_videos = st.number_input(
                "æ¯ä¸ªé¢‘é“åˆ†æè§†é¢‘æ•°",
                min_value=5,
                max_value=50,
                value=10,
                step=5,
                help="åˆ†ææ¯ä¸ªé¢‘é“æ—¶æŠ“å–çš„è§†é¢‘æ•°é‡"
            )
        
        with col2:
            rate_limit = st.number_input(
                "è¯·æ±‚é—´éš”(ç§’)",
                min_value=1,
                max_value=10,
                value=2,
                step=1,
                help="æ¯æ¬¡è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿæ—¶é—´ï¼Œé¿å…è¢«å°ç¦"
            )
            
            max_kols = st.number_input(
                "æœ€å¤§KOLæ•°é‡",
                min_value=100,
                max_value=10000,
                value=1000,
                step=100,
                help="è¾¾åˆ°æ­¤æ•°é‡ååœæ­¢å‘ç°æ–°KOL"
            )
        
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            st.success("é…ç½®å·²ä¿å­˜ï¼")


def render_data_browser():
    """æ¸²æŸ“æ•°æ®æµè§ˆé¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“‹ æ•°æ®æµè§ˆå™¨</div>', unsafe_allow_html=True)
    
    if not st.session_state.repository:
        st.warning("è¯·å…ˆè¿æ¥æ•°æ®åº“")
        return
    
    # ç­›é€‰é€‰é¡¹
    col1, col2, col3 = st.columns(3)
    
    with col1:
        status_filter = st.selectbox(
            "çŠ¶æ€ç­›é€‰",
            ["å…¨éƒ¨", "åˆæ ¼", "å¾…åˆ†æ", "å·²æ‹’ç»"],
            index=1
        )
    
    with col2:
        sort_by = st.selectbox(
            "æ’åºæ–¹å¼",
            ["AIå æ¯”", "è®¢é˜…æ•°", "å¹³å‡è§‚çœ‹", "å‘ç°æ—¶é—´"],
            index=0
        )
    
    with col3:
        limit = st.number_input(
            "æ˜¾ç¤ºæ•°é‡",
            min_value=10,
            max_value=1000,
            value=50,
            step=10
        )
    
    # æ„å»ºæŸ¥è¯¢
    status_map = {
        "å…¨éƒ¨": None,
        "åˆæ ¼": "qualified",
        "å¾…åˆ†æ": "pending",
        "å·²æ‹’ç»": "rejected"
    }
    
    sort_map = {
        "AIå æ¯”": "ai_ratio DESC",
        "è®¢é˜…æ•°": "subscribers DESC",
        "å¹³å‡è§‚çœ‹": "avg_views DESC",
        "å‘ç°æ—¶é—´": "discovered_at DESC"
    }
    
    # æŸ¥è¯¢æ•°æ®
    query = "SELECT * FROM kols"
    if status_filter != "å…¨éƒ¨":
        query += f" WHERE status = '{status_map[status_filter]}'"
    query += f" ORDER BY {sort_map[sort_by]} LIMIT {limit}"
    
    kols = st.session_state.db.fetchall(query)
    
    if kols:
        df = pd.DataFrame(kols)
        
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_columns = [
            'channel_name', 'channel_url', 'subscribers', 'total_videos', 'ai_ratio',
            'avg_views', 'avg_likes', 'engagement_rate', 'status', 'discovered_at'
        ]
        
        display_df = df[display_columns].copy()
        
        display_df.columns = [
            'é¢‘é“åç§°', 'é¢‘é“é“¾æ¥', 'è®¢é˜…æ•°', 'æ€»è§†é¢‘', 'AIå æ¯”',
            'å¹³å‡è§‚çœ‹', 'å¹³å‡ç‚¹èµ', 'äº’åŠ¨ç‡', 'çŠ¶æ€', 'å‘ç°æ—¶é—´'
        ]
        
        # æ ¼å¼åŒ–æ•°æ®
        display_df['æ€»è§†é¢‘'] = display_df['æ€»è§†é¢‘'].apply(lambda x: str(int(x)))
        display_df['AIå æ¯”'] = display_df['AIå æ¯”'].apply(lambda x: f"{x*100:.1f}%")
        display_df['äº’åŠ¨ç‡'] = display_df['äº’åŠ¨ç‡'].apply(lambda x: f"{x:.2f}%")
        display_df['è®¢é˜…æ•°'] = display_df['è®¢é˜…æ•°'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡è§‚çœ‹'] = display_df['å¹³å‡è§‚çœ‹'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡ç‚¹èµ'] = display_df['å¹³å‡ç‚¹èµ'].apply(lambda x: f"{x:,}")
        
        # æ ¼å¼åŒ–æ—¶é—´ - å°†UTCæ—¶é—´è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
        def format_time(dt):
            if pd.isna(dt):
                return ""
            if isinstance(dt, str):
                dt = pd.to_datetime(dt)
            # åŠ 8å°æ—¶è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
            dt_beijing = dt + pd.Timedelta(hours=8)
            return dt_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        display_df['å‘ç°æ—¶é—´'] = display_df['å‘ç°æ—¶é—´'].apply(format_time)
        
        # åŠ¨æ€è®¡ç®—è¡¨æ ¼é«˜åº¦ï¼šæ¯è¡Œçº¦35pxï¼ŒåŠ ä¸Šè¡¨å¤´50px
        table_height = min(max(len(display_df) * 35 + 50, 200), 800)
        
        st.dataframe(
            display_df, 
            width='stretch', 
            hide_index=True, 
            height=table_height,
            column_config={
                "é¢‘é“é“¾æ¥": st.column_config.LinkColumn(
                    "é¢‘é“é“¾æ¥",
                    help="ç‚¹å‡»æ‰“å¼€YouTubeé¢‘é“"
                ),
                "æ€»è§†é¢‘": st.column_config.TextColumn(
                    "æ€»è§†é¢‘"
                )
            }
        )
        
        # å¯¼å‡ºæŒ‰é’®
        st.divider()
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            if st.button("ğŸ“¥ å¯¼å‡ºExcel", key="export_excel"):
                from tasks.export_task import ExportTask
                export_task = ExportTask(st.session_state.repository)
                filepath = export_task.run()
                if filepath:
                    st.success(f"âœ… å¯¼å‡ºæˆåŠŸ: {filepath}")
                    add_log(f"å¯¼å‡ºExcel: {filepath}", "SUCCESS")
        
        with col2:
            csv = display_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSV",
                data=csv,
                file_name=f"kol_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    else:
        st.info("æš‚æ— æ•°æ®")


def clear_logs():
    """æ¸…ç©ºæ—¥å¿—"""
    global log_list
    log_list.clear()
    
    # æ¸…ç©ºæ—¥å¿—æ–‡ä»¶
    log_file = os.path.join(LOG_DIR, f"{datetime.now().strftime('%Y%m%d')}.log")
    if os.path.exists(log_file):
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write("")
            return True
        except Exception as e:
            return False
    return True


def render_logs():
    """æ¸²æŸ“æ—¥å¿—æŸ¥çœ‹é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“ å®æ—¶æ—¥å¿—</div>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–è‡ªåŠ¨åˆ·æ–°çŠ¶æ€ - é»˜è®¤å¼€å¯
    if 'auto_refresh_enabled' not in st.session_state:
        st.session_state.auto_refresh_enabled = True
    
    # ä»æ–‡ä»¶è¯»å–çˆ¬è™«çŠ¶æ€ï¼ˆæ¯æ¬¡éƒ½é‡æ–°è¯»å–ï¼Œç¡®ä¿æœ€æ–°ï¼‰
    crawler_is_running = is_crawler_running()
    
    # æ—¥å¿—æ§åˆ¶
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°æ—¥å¿—", key="refresh_logs_btn"):
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—", key="clear_logs_btn"):
            if clear_logs():
                st.success("âœ… æ—¥å¿—å·²æ¸…ç©º")
                time.sleep(0.5)
                st.rerun()
            else:
                st.error("âŒ æ¸…ç©ºæ—¥å¿—å¤±è´¥")
    
    with col3:
        # è‡ªåŠ¨åˆ·æ–°é€‰é¡¹
        auto_refresh = st.checkbox(
            "è‡ªåŠ¨åˆ·æ–° (æ¯3ç§’)", 
            value=st.session_state.auto_refresh_enabled,
            key="auto_refresh_checkbox_unique",
            help="çˆ¬è™«è¿è¡Œæ—¶è‡ªåŠ¨åˆ·æ–°æ—¥å¿—"
        )
        # æ›´æ–°çŠ¶æ€
        if auto_refresh != st.session_state.auto_refresh_enabled:
            st.session_state.auto_refresh_enabled = auto_refresh
    
    # æ˜¾ç¤ºæ—¥å¿—
    st.divider()
    
    # è¯»å–æ—¥å¿— - åªä»æ–‡ä»¶è¯»å–ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
    log_file = os.path.join(LOG_DIR, f"{datetime.now().strftime('%Y%m%d')}.log")
    all_logs = []
    
    # è¯»å–æ–‡ä»¶æ—¥å¿—
    if os.path.exists(log_file):
        try:
            # å°è¯•å¤šç§ç¼–ç è¯»å–
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            for encoding in encodings:
                try:
                    with open(log_file, 'r', encoding=encoding) as f:
                        file_logs = f.readlines()
                        all_logs = [line.strip() for line in file_logs if line.strip()]
                    break
                except UnicodeDecodeError:
                    continue
        except Exception as e:
            st.error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºæ—¥å¿—æ•°é‡å’ŒçŠ¶æ€
    log_count = len(all_logs)
    display_count = min(log_count, 200)
    
    # çŠ¶æ€æ  - æ”¹è¿›UIï¼Œç§»é™¤å‘¼å¸æ•ˆæœ
    if crawler_is_running:
        st.markdown("""
        <div style="background: linear-gradient(90deg, #1e3a8a 0%, #3b82f6 100%); 
                    padding: 15px; border-radius: 10px; margin-bottom: 10px;">
            <div style="display: flex; align-items: center; justify-content: space-between;">
                <div style="display: flex; align-items: center;">
                    <div style="width: 12px; height: 12px; background: #22c55e; 
                                border-radius: 50%; margin-right: 10px;"></div>
                    <span style="color: white; font-size: 18px; font-weight: bold;">
                        ğŸ”„ çˆ¬è™«è¿è¡Œä¸­...
                    </span>
                </div>
                <span style="color: #e0e7ff; font-size: 14px;">
                    å…± {log_count} æ¡æ—¥å¿— | æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡
                </span>
            </div>
        </div>
        """.format(log_count=log_count, display_count=display_count), unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div style="background: linear-gradient(90deg, #065f46 0%, #10b981 100%); 
                    padding: 15px; border-radius: 10px; margin-bottom: 10px;">
            <div style="display: flex; align-items: center; justify-content: space-between;">
                <div style="display: flex; align-items: center;">
                    <span style="color: white; font-size: 18px; font-weight: bold;">
                        âœ… çˆ¬è™«å·²åœæ­¢
                    </span>
                </div>
                <span style="color: #d1fae5; font-size: 14px;">
                    å…± {log_count} æ¡æ—¥å¿— | æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡
                </span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    if all_logs:
        # æ˜¾ç¤ºæœ€æ–°çš„æ—¥å¿—ï¼ˆæœ€æ–°çš„åœ¨æœ€ä¸‹é¢ï¼‰
        logs_text = "\n".join(all_logs[-200:])  # æ˜¾ç¤ºæœ€è¿‘200æ¡
        
        # ä½¿ç”¨HTMLå®¹å™¨ + è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        st.markdown("""
        <style>
        .log-container {
            background-color: #1e1e1e;
            color: #d4d4d4;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 13px;
            padding: 15px;
            border-radius: 5px;
            height: 500px;
            overflow-y: auto;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .log-container::-webkit-scrollbar {
            width: 10px;
        }
        .log-container::-webkit-scrollbar-track {
            background: #2d2d2d;
        }
        .log-container::-webkit-scrollbar-thumb {
            background: #555;
            border-radius: 5px;
        }
        .log-container::-webkit-scrollbar-thumb:hover {
            background: #777;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # åˆ›å»ºæ—¥å¿—å®¹å™¨ - ä½¿ç”¨å”¯ä¸€ID
        log_container_id = f"log_container_{int(time.time() * 1000)}"
        
        # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
        import html
        logs_html = html.escape(logs_text)
        
        st.markdown(
            f'<div class="log-container" id="{log_container_id}">{logs_html}</div>',
            unsafe_allow_html=True
        )
        
        # JavaScriptè‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨ - ä½¿ç”¨setTimeoutç¡®ä¿DOMåŠ è½½å®Œæˆ
        st.markdown(f"""
        <script>
        setTimeout(function() {{
            var container = document.getElementById('{log_container_id}');
            if (container) {{
                container.scrollTop = container.scrollHeight;
            }}
        }}, 100);
        </script>
        """, unsafe_allow_html=True)
    else:
        st.info("æš‚æ— æ—¥å¿—è®°å½•")
    
    # è‡ªåŠ¨åˆ·æ–°é€»è¾‘ - ç®€åŒ–ï¼Œç›´æ¥sleepårerun
    if st.session_state.auto_refresh_enabled and crawler_is_running:
        time.sleep(3)
        st.rerun()


def render_ai_rules():
    """æ¸²æŸ“AIè§„åˆ™é…ç½®é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ¯ AIè¿‡æ»¤è§„åˆ™é…ç½®</div>', unsafe_allow_html=True)
    
    st.info("ğŸ’¡ é…ç½®AIå†…å®¹è¯†åˆ«è§„åˆ™ï¼Œè°ƒæ•´å…³é”®è¯å’Œç­›é€‰æ¡ä»¶")
    
    # è¯»å–é…ç½®
    with open('config/config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # åŸºç¡€å‚æ•°é…ç½®
    st.subheader("ğŸ“Š åŸºç¡€ç­›é€‰å‚æ•°")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**AIå†…å®¹å æ¯”é˜ˆå€¼**")
        # Sliderç›´æ¥ä½¿ç”¨0-100çš„èŒƒå›´ï¼Œæ˜¾ç¤ºç™¾åˆ†æ¯”
        ai_ratio_percentage = st.slider(
            "AIå æ¯”",
            min_value=0,
            max_value=100,
            value=int(config['crawler']['ai_ratio_threshold'] * 100),
            step=5,
            format="%d%%",
            help="åªæœ‰AIå†…å®¹å æ¯”è¶…è¿‡æ­¤é˜ˆå€¼çš„é¢‘é“æ‰ä¼šè¢«æ ‡è®°ä¸ºåˆæ ¼",
            label_visibility="collapsed"
        )
        # è½¬æ¢å›0-1çš„å°æ•°ç”¨äºä¿å­˜
        ai_ratio_threshold = ai_ratio_percentage / 100.0
    
    with col2:
        sample_video_count = st.number_input(
            "æ¯ä¸ªé¢‘é“åˆ†æè§†é¢‘æ•°",
            min_value=5,
            max_value=50,
            value=config['crawler']['sample_video_count'],
            step=5,
            help="åˆ†ææ¯ä¸ªé¢‘é“æ—¶æŠ“å–çš„è§†é¢‘æ•°é‡ï¼Œè¶Šå¤šè¶Šå‡†ç¡®ä½†è¶Šæ…¢"
        )
    
    with col3:
        active_days_threshold = st.number_input(
            "æ´»è·ƒåº¦é˜ˆå€¼(å¤©)",
            min_value=30,
            max_value=365,
            value=config['crawler']['active_days_threshold'],
            step=30,
            help="æœ€åä¸€æ¬¡å‘å¸ƒè§†é¢‘è·ä»Šçš„å¤©æ•°ï¼Œè¶…è¿‡æ­¤å€¼è§†ä¸ºä¸æ´»è·ƒ"
        )
    
    st.divider()
    
    # AIå…³é”®è¯é…ç½®
    st.subheader("ğŸ”‘ AIå…³é”®è¯åº“")
    
    st.markdown("""
    **å…³é”®è¯åŒ¹é…è§„åˆ™**ï¼š
    - âœ… **ä¸åŒºåˆ†å¤§å°å†™**ï¼š'AI' å’Œ 'ai' æ•ˆæœç›¸åŒ
    - âœ… **éƒ¨åˆ†åŒ¹é…**ï¼š'AI' å¯ä»¥åŒ¹é… 'AI video'ã€'using AI' ç­‰
    - âœ… **åŒé‡æ£€æŸ¥**ï¼šåŒæ—¶æ£€æŸ¥è§†é¢‘æ ‡é¢˜å’Œæè¿°
    - âœ… **å®½æ¾åŒ¹é…**ï¼šåªè¦åŒ¹é…ä»»æ„ä¸€ä¸ªå…³é”®è¯å°±åˆ¤å®šä¸ºAIç›¸å…³
    - âœ… **ä¼˜å…ˆçº§è¯´æ˜**ï¼šé«˜/ä¸­/ä½ä¼˜å…ˆçº§ä»…ç”¨äºç»„ç»‡ç®¡ç†ï¼ŒåŒ¹é…æƒé‡ç›¸åŒ
    """)
    
    tab1, tab2, tab3 = st.tabs(["ğŸ”¥ é«˜ä¼˜å…ˆçº§", "â­ ä¸­ä¼˜å…ˆçº§", "ğŸ“Œ ä½ä¼˜å…ˆçº§"])
    
    with tab1:
        st.caption("ğŸ’¡ æœ€æ–°AIå·¥å…·å’Œçƒ­é—¨è¯é¢˜ï¼ˆå¦‚ï¼šSora, Kling, Runwayç­‰ï¼‰")
        high_keywords = st.text_area(
            "é«˜ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
            value="\n".join(config['keywords']['priority_high']),
            height=200,
            help="è¾“å…¥æœ€æ–°ã€æœ€çƒ­é—¨çš„AIå·¥å…·åç§°"
        )
        newline = '\n'
        st.caption(f"âœ“ å½“å‰æ•°é‡: {len([k for k in high_keywords.split(newline) if k.strip()])} ä¸ª")
    
    with tab2:
        st.caption("ğŸ’¡ ä¸»æµAIå·¥å…·å’Œå¸¸è§æœ¯è¯­ï¼ˆå¦‚ï¼šChatGPT, Midjourney, Claudeç­‰ï¼‰")
        medium_keywords = st.text_area(
            "ä¸­ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
            value="\n".join(config['keywords']['priority_medium']),
            height=200,
            help="è¾“å…¥ä¸»æµã€å¸¸ç”¨çš„AIå·¥å…·å’Œæœ¯è¯­"
        )
        st.caption(f"âœ“ å½“å‰æ•°é‡: {len([k for k in medium_keywords.split(newline) if k.strip()])} ä¸ª")
    
    with tab3:
        st.caption("ğŸ’¡ æŠ€æœ¯æœ¯è¯­å’Œä¸“ä¸šè¯æ±‡ï¼ˆå¦‚ï¼šLLM, Diffusion Model, AI workflowç­‰ï¼‰")
        low_keywords = st.text_area(
            "ä½ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
            value="\n".join(config['keywords']['priority_low']),
            height=200,
            help="è¾“å…¥æŠ€æœ¯æ€§è¾ƒå¼ºçš„ä¸“ä¸šæœ¯è¯­"
        )
        st.caption(f"âœ“ å½“å‰æ•°é‡: {len([k for k in low_keywords.split(newline) if k.strip()])} ä¸ª")
    
    st.divider()
    
    # æ’é™¤è§„åˆ™é…ç½®
    st.subheader("ğŸš« æ’é™¤è§„åˆ™")
    
    st.markdown("""
    **æ’é™¤è§„åˆ™è¯´æ˜**ï¼š
    - âš ï¸ **åŒ¹é…æ–¹å¼**ï¼šé¢‘é“åç§°æˆ–è§†é¢‘æ ‡é¢˜ä¸­åŒ…å«è¿™äº›å…³é”®è¯å°†è¢«è‡ªåŠ¨æ’é™¤
    - ğŸ’¡ **å¸¸è§ç±»å‹**ï¼šè¯¾ç¨‹/æ•™å­¦ï¼ˆç¬¬ã€è®²ã€è¯¾ï¼‰ã€å­¦æœ¯æœºæ„ï¼ˆå¤§å­¦ã€ç ”ç©¶æ‰€ï¼‰ã€æ–°é—»åª’ä½“ï¼ˆnewsã€æ–°é—»ï¼‰ç­‰
    - âœï¸ **å®Œå…¨è‡ªå®šä¹‰**ï¼šä½ å¯ä»¥æ·»åŠ ä»»ä½•æƒ³è¦æ’é™¤çš„å…³é”®è¯ï¼Œä¸é™äºä¸Šè¿°åˆ†ç±»
    - ğŸ¯ **ç›®çš„**ï¼šè¿‡æ»¤æ‰éç›®æ ‡KOLï¼Œèšç„¦äºAIå†…å®¹åˆ›ä½œè€…
    """)
    
    # åˆå¹¶æ‰€æœ‰æ’é™¤å…³é”®è¯åˆ°ä¸€ä¸ªåˆ—è¡¨
    all_exclusion_keywords = []
    all_exclusion_keywords.extend(config['exclusion_rules'].get('course_keywords', []))
    all_exclusion_keywords.extend(config['exclusion_rules'].get('academic_keywords', []))
    all_exclusion_keywords.extend(config['exclusion_rules'].get('news_keywords', []))
    
    exclusion_keywords = st.text_area(
        "æ’é™¤å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        value="\n".join(all_exclusion_keywords),
        height=300,
        help="è¾“å…¥ä»»ä½•ä½ æƒ³æ’é™¤çš„å…³é”®è¯ï¼Œå¦‚ï¼šè¯¾ç¨‹ã€å¤§å­¦ã€æ–°é—»ã€tutorialã€universityç­‰"
    )
    
    keyword_count = len([k for k in exclusion_keywords.split(newline) if k.strip()])
    st.caption(f"âœ“ å½“å‰å…± {keyword_count} ä¸ªæ’é™¤å…³é”®è¯")
    
    # æ˜¾ç¤ºä¸€äº›å¸¸ç”¨ç¤ºä¾‹
    with st.expander("ğŸ’¡ å¸¸ç”¨æ’é™¤å…³é”®è¯å‚è€ƒ", expanded=False):
        st.markdown("""
        **è¯¾ç¨‹/æ•™å­¦ç±»**ï¼šç¬¬ã€è®²ã€è¯¾ã€lessonã€lectureã€tutorialã€æ•™ç¨‹ã€æ•™å­¦ã€ç³»åˆ—è¯¾
        
        **å­¦æœ¯æœºæ„ç±»**ï¼šuniversityã€å¤§å­¦ã€collegeã€å­¦é™¢ã€instituteã€ç ”ç©¶æ‰€ã€å®éªŒå®¤
        
        **æ–°é—»åª’ä½“ç±»**ï¼šnewsã€æ–°é—»ã€mediaã€åª’ä½“ã€æŠ¥å¯¼ã€æŠ¥é“ã€é¢‘é“
        
        **å…¶ä»–ç±»å‹**ï¼šä½ å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ ä»»ä½•å…³é”®è¯
        """)
    
    st.divider()
    
    # ä¿å­˜æŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
            # æ›´æ–°é…ç½®
            config['crawler']['ai_ratio_threshold'] = ai_ratio_threshold
            config['crawler']['sample_video_count'] = sample_video_count
            config['crawler']['active_days_threshold'] = active_days_threshold
            
            config['keywords']['priority_high'] = [k.strip() for k in high_keywords.split(newline) if k.strip()]
            config['keywords']['priority_medium'] = [k.strip() for k in medium_keywords.split(newline) if k.strip()]
            config['keywords']['priority_low'] = [k.strip() for k in low_keywords.split(newline) if k.strip()]
            
            # ä¿å­˜ç»Ÿä¸€çš„æ’é™¤å…³é”®è¯åˆ—è¡¨ï¼ˆä¸ºäº†å…¼å®¹æ€§ï¼Œä»ç„¶ä¿å­˜åˆ°ä¸‰ä¸ªåˆ†ç±»ä¸­ï¼Œä½†å®é™…ä½¿ç”¨æ—¶ä¼šåˆå¹¶ï¼‰
            exclusion_list = [k.strip() for k in exclusion_keywords.split(newline) if k.strip()]
            config['exclusion_rules']['course_keywords'] = exclusion_list
            config['exclusion_rules']['academic_keywords'] = []
            config['exclusion_rules']['news_keywords'] = []
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            try:
                with open('config/config.json', 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                st.success("âœ… é…ç½®å·²ä¿å­˜ï¼æ–°é…ç½®å°†åœ¨ä¸‹æ¬¡çˆ¬è™«ä»»åŠ¡æ—¶ç”Ÿæ•ˆ")
                add_log("AIè§„åˆ™é…ç½®å·²æ›´æ–°", "INFO")
            except Exception as e:
                st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    
    with col2:
        if st.button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤", use_container_width=True):
            st.warning("âš ï¸ æ­¤æ“ä½œå°†æ¢å¤é»˜è®¤é…ç½®ï¼Œç¡®å®šè¦ç»§ç»­å—ï¼Ÿ")
            if st.button("ç¡®è®¤é‡ç½®"):
                st.info("è¯·æ‰‹åŠ¨ç¼–è¾‘ config/config.json æ–‡ä»¶æ¢å¤é»˜è®¤å€¼")
    
    # æ˜¾ç¤ºå½“å‰é…ç½®æ‘˜è¦
    st.divider()
    st.subheader("ğŸ“‹ å½“å‰é…ç½®æ‘˜è¦")
    
    summary_col1, summary_col2, summary_col3 = st.columns(3)
    
    with summary_col1:
        st.metric("AIå æ¯”é˜ˆå€¼", f"{ai_ratio_threshold*100:.0f}%")
        st.metric("åˆ†æè§†é¢‘æ•°", f"{sample_video_count} ä¸ª")
    
    with summary_col2:
        total_keywords = len([k for k in high_keywords.split(newline) if k.strip()]) + \
                        len([k for k in medium_keywords.split(newline) if k.strip()]) + \
                        len([k for k in low_keywords.split(newline) if k.strip()])
        st.metric("æ€»å…³é”®è¯æ•°", f"{total_keywords} ä¸ª")
        st.metric("æ´»è·ƒåº¦é˜ˆå€¼", f"{active_days_threshold} å¤©")
    
    with summary_col3:
        total_exclusions = len([k for k in exclusion_keywords.split(newline) if k.strip()])
        st.metric("æ’é™¤è§„åˆ™æ•°", f"{total_exclusions} ä¸ª")


def render_settings():
    """æ¸²æŸ“è®¾ç½®é¡µé¢"""
    st.markdown('<div class="main-header">âš™ï¸ ç³»ç»Ÿè®¾ç½®</div>', unsafe_allow_html=True)
    
    # æ•°æ®åº“è®¾ç½®
    st.subheader("ğŸ—„ï¸ æ•°æ®åº“é…ç½®")
    
    st.info("ğŸ’¡ å½“å‰ä½¿ç”¨SQLiteæ•°æ®åº“ï¼Œæ•°æ®ä¿å­˜åœ¨ data/ai_kol_crawler.db")
    
    with open('config/config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    col1, col2 = st.columns(2)
    
    with col1:
        db_host = st.text_input("æ•°æ®åº“åœ°å€", value=config['database'].get('host', 'localhost'), disabled=True)
        db_port = st.number_input("ç«¯å£", value=config['database'].get('port', 5432), disabled=True)
    
    with col2:
        db_name = st.text_input("æ•°æ®åº“å", value=config['database'].get('database', 'ai_kol_crawler'), disabled=True)
        db_user = st.text_input("ç”¨æˆ·å", value=config['database'].get('user', 'postgres'), disabled=True)
    
    st.caption("ğŸ’¡ æç¤º: SQLiteæ•°æ®åº“æ— éœ€é…ç½®ï¼Œå¦‚éœ€ä½¿ç”¨PostgreSQLè¯·ä¿®æ”¹ config/config.json")
    
    st.divider()
    
    # å¯¼å‡ºè®¾ç½®
    st.subheader("ğŸ“¤ å¯¼å‡ºè®¾ç½®")
    
    col1, col2 = st.columns(2)
    
    with col1:
        output_dir = st.text_input("å¯¼å‡ºç›®å½•", value=config['export']['output_dir'])
    
    with col2:
        sort_by = st.selectbox(
            "é»˜è®¤æ’åº",
            ["ai_ratio", "subscribers", "avg_views"],
            index=["ai_ratio", "subscribers", "avg_views"].index(config['export']['sort_by'])
        )
    
    st.divider()
    
    # æ•°æ®åº“ç®¡ç†
    st.subheader("ğŸ—‚ï¸ æ•°æ®åº“ç®¡ç†")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š æŸ¥çœ‹æ•°æ®åº“å¤§å°", use_container_width=True):
            import os
            db_path = 'data/ai_kol_crawler.db'
            if os.path.exists(db_path):
                size = os.path.getsize(db_path) / 1024 / 1024  # MB
                st.info(f"æ•°æ®åº“å¤§å°: {size:.2f} MB")
            else:
                st.warning("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
    
    with col2:
        if st.button("ğŸ’¾ å¤‡ä»½æ•°æ®åº“", use_container_width=True):
            import shutil
            from datetime import datetime
            try:
                backup_name = f"data/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
                shutil.copy('data/ai_kol_crawler.db', backup_name)
                st.success(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_name}")
            except Exception as e:
                st.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
    
    with col3:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®åº“", use_container_width=True):
            st.warning("âš ï¸ æ­¤æ“ä½œå°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œæ— æ³•æ¢å¤ï¼")
            confirm = st.checkbox("æˆ‘ç¡®è®¤è¦æ¸…ç©ºæ•°æ®åº“")
            if confirm and st.button("ç¡®è®¤æ¸…ç©º"):
                try:
                    if st.session_state.db:
                        st.session_state.db.execute("DELETE FROM videos")
                        st.session_state.db.execute("DELETE FROM expansion_queue")
                        st.session_state.db.execute("DELETE FROM kols")
                        st.success("âœ… æ•°æ®åº“å·²æ¸…ç©º")
                except Exception as e:
                    st.error(f"âŒ æ¸…ç©ºå¤±è´¥: {e}")
    
    st.divider()
    
    # ç³»ç»Ÿä¿¡æ¯
    st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ç‰ˆæœ¬ä¿¡æ¯**")
        st.write("- ç³»ç»Ÿç‰ˆæœ¬: v1.0")
        st.write("- æ•°æ®åº“: SQLite")
        st.write("- Pythonç‰ˆæœ¬:", sys.version.split()[0])
    
    with col2:
        st.write("**ç»Ÿè®¡ä¿¡æ¯**")
        stats = get_statistics()
        st.write(f"- æ€»KOLæ•°: {stats['total_kols']}")
        st.write(f"- åˆæ ¼KOLæ•°: {stats['qualified_kols']}")
        st.write(f"- æ€»è§†é¢‘æ•°: {stats['total_videos']}")


if __name__ == "__main__":
    """ä¸»ç¨‹åº"""
    init_session_state()
    
    # åˆå§‹åŒ–è·³è½¬æ ‡è®°å’Œå½“å‰é¡µé¢
    if 'jump_to_logs' not in st.session_state:
        st.session_state.jump_to_logs = False
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "ğŸ“Š ä»ªè¡¨ç›˜"
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("ğŸ¤– AI KOLçˆ¬è™«")
        st.caption("æ™ºèƒ½å‘ç°AIé¢†åŸŸKOL")
        st.title("å¯¼èˆªèœå•")
        
        # æ•°æ®åº“è¿æ¥çŠ¶æ€
        if connect_database():
            st.success("âœ… æ•°æ®åº“å·²è¿æ¥")
        else:
            st.error("âŒ æ•°æ®åº“æœªè¿æ¥")
        
        st.divider()
        
        # é¡µé¢é€‰æ‹©
        pages = ["ğŸ“Š ä»ªè¡¨ç›˜", "ğŸš€ çˆ¬è™«æ§åˆ¶", "ğŸ“‹ æ•°æ®æµè§ˆ", "ğŸ“ æ—¥å¿—æŸ¥çœ‹", "ğŸ¯ AIè§„åˆ™", "âš™ï¸ è®¾ç½®"]
        
        # å¦‚æœéœ€è¦è·³è½¬åˆ°æ—¥å¿—ï¼Œæ›´æ–°å½“å‰é¡µé¢
        if st.session_state.jump_to_logs:
            st.session_state.current_page = "ğŸ“ æ—¥å¿—æŸ¥çœ‹"
            st.session_state.jump_to_logs = False
        
        # è·å–å½“å‰é¡µé¢çš„ç´¢å¼•
        try:
            default_index = pages.index(st.session_state.current_page)
        except ValueError:
            default_index = 0
            st.session_state.current_page = pages[0]
        
        # ä½¿ç”¨keyæ¥ç¡®ä¿radioçŠ¶æ€æ­£ç¡®
        page = st.radio(
            "é€‰æ‹©é¡µé¢",
            pages,
            index=default_index,
            label_visibility="collapsed",
            key="page_selector"
        )
        
        # åªæœ‰å½“ç”¨æˆ·é€‰æ‹©çš„é¡µé¢ä¸å½“å‰é¡µé¢ä¸åŒæ—¶æ‰æ›´æ–°
        if page != st.session_state.current_page:
            st.session_state.current_page = page
            st.rerun()
        
        st.divider()
        
        # å¿«é€Ÿç»Ÿè®¡
        stats = get_statistics()
        st.metric("åˆæ ¼KOL", stats['qualified_kols'])
        st.metric("æ€»è§†é¢‘", stats['total_videos'])
        
        # çˆ¬è™«çŠ¶æ€æŒ‡ç¤º
        if is_crawler_running():
            st.warning("âš™ï¸ çˆ¬è™«è¿è¡Œä¸­...")
        
        st.divider()
        st.caption("AI KOLçˆ¬è™«ç³»ç»Ÿ v1.0")
        st.caption("Â© 2026 All Rights Reserved")
    
    # ä¸»å†…å®¹åŒº - ä½¿ç”¨å®¹å™¨éš”ç¦»æ¯ä¸ªé¡µé¢
    main_container = st.container()
    
    with main_container:
        if page == "ğŸ“Š ä»ªè¡¨ç›˜":
            render_dashboard()
        elif page == "ğŸš€ çˆ¬è™«æ§åˆ¶":
            render_crawler_control()
        elif page == "ğŸ“‹ æ•°æ®æµè§ˆ":
            render_data_browser()
        elif page == "ğŸ“ æ—¥å¿—æŸ¥çœ‹":
            render_logs()
        elif page == "ğŸ¯ AIè§„åˆ™":
            render_ai_rules()
        elif page == "âš™ï¸ è®¾ç½®":
            render_settings()
