# -*- coding: utf-8 -*-
"""
å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿ - Streamlit Webç•Œé¢
æ”¯æŒYouTubeã€GitHubç­‰å¤šä¸ªå¹³å°
"""
import streamlit as st
import pandas as pd
import time
import threading
import queue
from datetime import datetime
import json
import os
import sys
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, PROJECT_ROOT)
os.chdir(PROJECT_ROOT)

# çŠ¶æ€æ–‡ä»¶å’Œæ—¥å¿—ç›®å½•è·¯å¾„
CRAWLER_STATUS_FILE = os.path.join(PROJECT_ROOT, "data", "crawler_status.txt")
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSS
st.markdown("""
<style>
    /* éšè—Streamlité»˜è®¤å…ƒç´  */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* ä¾§è¾¹æ å®¹å™¨ - æœ€å°åŒ–é—´è· */
    section[data-testid="stSidebar"] {
        padding-top: 0.3rem !important;
    }
    section[data-testid="stSidebar"] > div {
        padding-left: 0.3rem !important;
        padding-right: 0.3rem !important;
    }
    
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-header {
        font-size: 2rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        padding: 0.5rem 0;
        margin-bottom: 1rem;
    }
    
    /* ä¾§è¾¹æ æ‰€æœ‰æŒ‰é’® - å®Œå…¨é€æ˜æ— èƒŒæ™¯ */
    section[data-testid="stSidebar"] button[kind="secondary"],
    section[data-testid="stSidebar"] button[kind="primary"] {
        background-color: transparent !important;
        background-image: none !important;
        border: none !important;
        box-shadow: none !important;
        color: #d0d0d0 !important;
        font-weight: 400 !important;
        font-size: 0.85rem !important;
        padding: 0.3rem 0.5rem !important;
        text-align: left !important;
        border-radius: 6px !important;
    }
    
    /* ä¾§è¾¹æ æŒ‰é’®æ‚¬åœ */
    section[data-testid="stSidebar"] button[kind="secondary"]:hover,
    section[data-testid="stSidebar"] button[kind="primary"]:hover {
        background-color: rgba(255, 255, 255, 0.05) !important;
        color: #ffffff !important;
    }
    
    /* ä¾§è¾¹æ æ¿€æ´»æŒ‰é’® */
    section[data-testid="stSidebar"] button[kind="primary"] {
        background-color: rgba(31, 119, 180, 0.15) !important;
        color: #4da3ff !important;
    }
    section[data-testid="stSidebar"] button[kind="primary"]:hover {
        background-color: rgba(31, 119, 180, 0.25) !important;
    }
    
    /* é¡¶çº§æŒ‰é’®ï¼ˆæ•°æ®æµè§ˆã€æ—¥å¿—ã€è®¾ç½®ï¼‰- åŠ ç²—çªå‡º */
    section[data-testid="stSidebar"] button[key*="data_browser"],
    section[data-testid="stSidebar"] button[key*="logs"],
    section[data-testid="stSidebar"] button[key*="settings"] {
        font-weight: 500 !important;
        font-size: 0.9rem !important;
        margin-top: 0.3rem !important;
        margin-bottom: 0.3rem !important;
    }
    
    /* ä¸»å†…å®¹åŒºæŒ‰é’®ä¿æŒåŸæ ·ï¼ˆæœ‰èƒŒæ™¯è‰²ï¼‰ */
    section[data-testid="stMain"] button {
        background-color: #1f77b4 !important;
        color: white !important;
        border: 1px solid #1f77b4 !important;
        border-radius: 6px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
    }
    section[data-testid="stMain"] button:hover {
        background-color: #1565c0 !important;
        border-color: #1565c0 !important;
    }
    
    /* å‡å°ä¾§è¾¹æ å…ƒç´ é—´è· */
    section[data-testid="stSidebar"] [data-testid="stVerticalBlock"] > div {
        gap: 0.05rem !important;
    }
    
    /* ä¾§è¾¹æ åˆ†ç±»æ ‡é¢˜ */
    section[data-testid="stSidebar"] h3 {
        font-size: 0.75rem !important;
        font-weight: 600 !important;
        color: #888 !important;
        margin-top: 0.3rem !important;
        margin-bottom: 0.2rem !important;
        text-transform: uppercase !important;
        letter-spacing: 0.5px !important;
    }
    
    /* ä¾§è¾¹æ ç»Ÿè®¡æ•°å­— */
    .stat-number {
        font-size: 1.5rem;
        font-weight: 700;
        color: #4da3ff;
        margin: 0.1rem 0;
        line-height: 1;
    }
    
    /* ä¾§è¾¹æ caption */
    section[data-testid="stSidebar"] p[class*="caption"] {
        font-size: 0.7rem !important;
        color: #888 !important;
        margin-bottom: 0.2rem !important;
    }
    
    /* åˆ†å‰²çº¿ */
    section[data-testid="stSidebar"] hr {
        margin: 0.3rem 0 !important;
        border-color: rgba(255, 255, 255, 0.1) !important;
    }
    
    /* ä¾§è¾¹æ æ ‡é¢˜ */
    section[data-testid="stSidebar"] h1 {
        margin-bottom: 0.1rem !important;
        padding-bottom: 0 !important;
        font-size: 1rem !important;
    }
    
    /* å¯¼å‡ºæŒ‰é’®æ ·å¼ */
    .export-buttons {
        display: flex;
        gap: 1rem;
        margin-top: 1rem;
    }
    
    /* æ•°æ®è¡¨æ ·å¼ */
    .dataframe {
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# å…¨å±€æ—¥å¿—é˜Ÿåˆ—
log_queue = queue.Queue()
log_list = []

def add_log(message, level="INFO"):
    """æ·»åŠ æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] [{level}] {message}"
    log_queue.put(log_entry)
    log_list.append(log_entry)
    if len(log_list) > 1000:
        log_list.pop(0)
    
    # å†™å…¥æ–‡ä»¶
    try:
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        log_file = f"{log_dir}/{datetime.now().strftime('%Y%m%d')}.log"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry + "\n")
    except:
        pass

def set_crawler_running(status):
    """è®¾ç½®çˆ¬è™«è¿è¡ŒçŠ¶æ€"""
    try:
        status_dir = os.path.dirname(CRAWLER_STATUS_FILE)
        os.makedirs(status_dir, exist_ok=True)
        with open(CRAWLER_STATUS_FILE, 'w', encoding='utf-8') as f:
            f.write("running" if status else "stopped")
    except:
        pass

def is_crawler_running():
    """è·å–çˆ¬è™«è¿è¡ŒçŠ¶æ€"""
    try:
        if os.path.exists(CRAWLER_STATUS_FILE):
            with open(CRAWLER_STATUS_FILE, 'r', encoding='utf-8') as f:
                status = f.read().strip()
                return status == "running"
    except:
        pass
    return False

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'db' not in st.session_state:
        st.session_state.db = None
    if 'youtube_repository' not in st.session_state:
        st.session_state.youtube_repository = None
    if 'github_repository' not in st.session_state:
        st.session_state.github_repository = None
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "youtube_dashboard"
    if 'jump_to_logs' not in st.session_state:
        st.session_state.jump_to_logs = False
    if 'auto_refresh_enabled' not in st.session_state:
        st.session_state.auto_refresh_enabled = True

def connect_database():
    """è¿æ¥æ•°æ®åº“"""
    try:
        if st.session_state.db is None:
            from storage.database import Database
            from storage.repositories.youtube_repository import YouTubeRepository
            from storage.repositories.github_repository import GitHubRepository
            
            db = Database()
            db.connect()
            db.init_tables()
            
            # å°è¯•è¿ç§»æ—§æ•°æ®
            try:
                from storage.migrations.migration_v2 import MigrationV2
                migration = MigrationV2()
                if migration.check_old_tables_exist():
                    add_log("æ£€æµ‹åˆ°æ—§ç‰ˆæ•°æ®ï¼Œæ­£åœ¨è¿ç§»...", "INFO")
                    migration.migrate()
                    add_log("æ•°æ®è¿ç§»å®Œæˆ", "INFO")
            except Exception as e:
                add_log(f"æ•°æ®è¿ç§»æ£€æŸ¥: {e}", "WARNING")
            
            st.session_state.db = db
            st.session_state.youtube_repository = YouTubeRepository(db)
            st.session_state.github_repository = GitHubRepository(db)
            return True
    except Exception as e:
        st.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
        return False
    return True

def get_statistics(platform='youtube'):
    """è·å–ç»Ÿè®¡æ•°æ®"""
    if platform == 'youtube' and st.session_state.youtube_repository:
        try:
            return st.session_state.youtube_repository.get_statistics()
        except:
            return {'total_kols': 0, 'qualified_kols': 0, 'pending_kols': 0, 'total_videos': 0, 'pending_expansions': 0}
    elif platform == 'github' and st.session_state.github_repository:
        try:
            return st.session_state.github_repository.get_statistics()
        except:
            return {'total_developers': 0, 'qualified_developers': 0, 'pending_developers': 0, 'total_repositories': 0}
    return {}

def clear_logs():
    """æ¸…ç©ºæ—¥å¿—"""
    global log_list
    log_list.clear()
    log_file = os.path.join(LOG_DIR, f"{datetime.now().strftime('%Y%m%d')}.log")
    if os.path.exists(log_file):
        try:
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write("")
            return True
        except:
            return False
    return True

def run_youtube_crawler_task(task_type, repository, **kwargs):
    """è¿è¡ŒYouTubeçˆ¬è™«ä»»åŠ¡"""
    try:
        from platforms.youtube.scraper import YouTubeScraper
        from platforms.youtube.searcher import KeywordSearcher
        from platforms.youtube.analyzer import KOLAnalyzer
        from platforms.youtube.expander import KOLExpander
        from platforms.youtube.filter import KOLFilter
        from tasks.youtube.discovery import YouTubeDiscoveryTask
        from tasks.youtube.expand import YouTubeExpandTask
        
        set_crawler_running(True)
        add_log(f"å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task_type}", "INFO")
        
        scraper = YouTubeScraper()
        searcher = KeywordSearcher(scraper)
        analyzer = KOLAnalyzer(scraper)
        expander = KOLExpander(scraper)
        filter_obj = KOLFilter(repository)
        
        if task_type == "discovery":
            task = YouTubeDiscoveryTask(searcher, analyzer, filter_obj, repository)
            keyword_limit = kwargs.get('keyword_limit', 30)
            add_log(f"ä½¿ç”¨ {keyword_limit} ä¸ªå…³é”®è¯è¿›è¡Œæœç´¢", "INFO")
            task.run(keyword_limit)
        elif task_type == "expand":
            task = YouTubeExpandTask(expander, analyzer, filter_obj, repository)
            add_log("å¼€å§‹æ‰©æ•£ä»»åŠ¡", "INFO")
            task.run()
        
        add_log(f"ä»»åŠ¡å®Œæˆ: {task_type}", "SUCCESS")
    except Exception as e:
        add_log(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        add_log(traceback.format_exc(), "ERROR")
    finally:
        set_crawler_running(False)

def run_github_crawler_task(task_type, repository, **kwargs):
    """è¿è¡ŒGitHubçˆ¬è™«ä»»åŠ¡"""
    try:
        from platforms.github.scraper import GitHubScraper
        from platforms.github.searcher import GitHubSearcher
        from platforms.github.analyzer import GitHubAnalyzer
        from tasks.github.discovery import GitHubDiscoveryTask
        
        set_crawler_running(True)
        add_log(f"å¼€å§‹æ‰§è¡ŒGitHubä»»åŠ¡: {task_type}", "INFO")
        
        scraper = GitHubScraper()
        searcher = GitHubSearcher(scraper, repository)  # ä¼ å…¥repositoryç”¨äºå»é‡
        analyzer = GitHubAnalyzer(scraper)
        
        if task_type == "discovery":
            task = GitHubDiscoveryTask(searcher, analyzer, repository)
            max_developers = kwargs.get('max_developers', 50)
            strategy = kwargs.get('strategy', 'comprehensive')
            task.run(max_developers=max_developers, strategy=strategy)
        
        add_log(f"GitHubä»»åŠ¡å®Œæˆ: {task_type}", "SUCCESS")
    except Exception as e:
        add_log(f"GitHubä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", "ERROR")
        add_log(traceback.format_exc(), "ERROR")
    finally:
        set_crawler_running(False)



def render_youtube_dashboard():
    """æ¸²æŸ“YouTubeä»ªè¡¨ç›˜"""
    st.markdown('<div class="main-header">ğŸ“Š YouTube æ•°æ®ä»ªè¡¨ç›˜</div>', unsafe_allow_html=True)
    
    stats = get_statistics('youtube')
    
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("æ€»KOLæ•°", stats.get('total_kols', 0))
    with col2:
        st.metric("åˆæ ¼KOL", stats.get('qualified_kols', 0))
    with col3:
        st.metric("å¾…åˆ†æ", stats.get('pending_kols', 0))
    with col4:
        st.metric("æ€»è§†é¢‘æ•°", stats.get('total_videos', 0))
    with col5:
        st.metric("å¾…æ‰©æ•£", stats.get('pending_expansions', 0))
    
    st.divider()
    st.subheader("ğŸŒŸ æœ€è¿‘å‘ç°çš„åˆæ ¼KOL")
    
    if st.session_state.youtube_repository:
        recent_kols = st.session_state.youtube_repository.get_qualified_kols(limit=10)
        if recent_kols:
            df = pd.DataFrame(recent_kols)
            display_df = df[['channel_name', 'subscribers', 'ai_ratio', 'avg_views', 'avg_comments', 'engagement_rate', 'discovered_at']].copy()
            display_df.columns = ['é¢‘é“åç§°', 'è®¢é˜…æ•°', 'AIå æ¯”', 'å¹³å‡è§‚çœ‹', 'å¹³å‡è¯„è®º', 'äº’åŠ¨ç‡', 'çˆ¬å–æ—¶é—´']
            display_df['AIå æ¯”'] = display_df['AIå æ¯”'].apply(lambda x: f"{x*100:.1f}%")
            display_df['äº’åŠ¨ç‡'] = display_df['äº’åŠ¨ç‡'].apply(lambda x: f"{x:.2f}%")
            display_df['è®¢é˜…æ•°'] = display_df['è®¢é˜…æ•°'].apply(lambda x: f"{x:,}")
            display_df['å¹³å‡è§‚çœ‹'] = display_df['å¹³å‡è§‚çœ‹'].apply(lambda x: f"{x:,}")
            display_df['å¹³å‡è¯„è®º'] = display_df['å¹³å‡è¯„è®º'].apply(lambda x: f"{x:,}")
            st.dataframe(display_df, width='stretch', hide_index=True)
        else:
            st.info("ğŸ“­ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«ä»»åŠ¡")
    
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", key="refresh_youtube_dashboard"):
        st.rerun()

def render_github_dashboard():
    """æ¸²æŸ“GitHubä»ªè¡¨ç›˜"""
    st.markdown('<div class="main-header">ğŸ“Š GitHub æ•°æ®ä»ªè¡¨ç›˜</div>', unsafe_allow_html=True)
    
    stats = get_statistics('github')
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»å¼€å‘è€…æ•°", stats.get('total_developers', 0))
    with col2:
        st.metric("åˆæ ¼å¼€å‘è€…", stats.get('qualified_developers', 0))
    with col3:
        st.metric("å¾…åˆ†æ", stats.get('pending_developers', 0))
    with col4:
        st.metric("æ€»ä»“åº“æ•°", stats.get('total_repositories', 0))
    
    st.divider()
    st.subheader("ğŸŒŸ æœ€è¿‘å‘ç°çš„ç‹¬ç«‹å¼€å‘è€…")
    
    if st.session_state.github_repository:
        recent_devs = st.session_state.github_repository.get_qualified_developers(limit=10)
        if recent_devs:
            df = pd.DataFrame(recent_devs)
            display_df = df[['username', 'name', 'followers', 'total_stars', 'discovered_at']].copy()
            display_df.columns = ['ç”¨æˆ·å', 'å§“å', 'Followers', 'æ€»Stars', 'å‘ç°æ—¶é—´']
            display_df['Followers'] = display_df['Followers'].apply(lambda x: f"{x:,}")
            display_df['æ€»Stars'] = display_df['æ€»Stars'].apply(lambda x: f"{x:,}")
            st.dataframe(display_df, width='stretch', hide_index=True)
        else:
            st.info("ğŸ“­ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«ä»»åŠ¡")
    
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", key="refresh_github_dashboard"):
        st.rerun()

def render_youtube_crawler():
    """æ¸²æŸ“YouTubeçˆ¬è™«æ§åˆ¶"""
    st.markdown('<div class="main-header">ğŸš€ YouTube çˆ¬è™«æ§åˆ¶</div>', unsafe_allow_html=True)
    
    running = is_crawler_running()
    if running:
        st.warning("âš ï¸ çˆ¬è™«æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        st.info("ğŸ’¡ åˆ‡æ¢åˆ°ã€ŒğŸ“ æ—¥å¿—æŸ¥çœ‹ã€é¡µé¢æŸ¥çœ‹å®æ—¶è¿›åº¦")
        if st.button("â¹ï¸ æ ‡è®°ä¸ºå·²å®Œæˆ", key="mark_complete"):
            set_crawler_running(False)
            st.rerun()
    else:
        st.success("âœ… çˆ¬è™«ç©ºé—²ï¼Œå¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡")
    
    st.divider()
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ” åˆå§‹å‘ç°ä»»åŠ¡")
        st.write("é€šè¿‡å…³é”®è¯æœç´¢YouTubeï¼Œå‘ç°æ–°çš„AI KOL")
        
        keyword_limit = st.slider(
            "ä½¿ç”¨å…³é”®è¯æ•°é‡",
            min_value=1,
            max_value=50,
            value=5,
            step=1,
            help="é€‰æ‹©è¦ä½¿ç”¨çš„å…³é”®è¯æ•°é‡ï¼Œæ•°é‡è¶Šå¤šå‘ç°çš„KOLè¶Šå¤šï¼Œä½†è€—æ—¶ä¹Ÿè¶Šé•¿"
        )
        
        st.info(f"é¢„è®¡æœç´¢ {keyword_limit * 5} ä¸ªé¢‘é“ï¼Œè€—æ—¶çº¦ {keyword_limit * 2} åˆ†é’Ÿ")
        
        if st.button("â–¶ï¸ å¼€å§‹åˆå§‹å‘ç°", disabled=running, key="start_youtube_discovery"):
                if not st.session_state.youtube_repository:
                    st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
                else:
                    clear_logs()
                    add_log("=" * 60, "INFO")
                    add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - YouTubeåˆå§‹å‘ç°", "INFO")
                    add_log("=" * 60, "INFO")
                    add_log(f"ç”¨æˆ·å¯åŠ¨åˆå§‹å‘ç°ä»»åŠ¡ï¼Œå…³é”®è¯æ•°é‡: {keyword_limit}", "INFO")
                    
                    thread = threading.Thread(
                        target=run_youtube_crawler_task,
                        args=("discovery", st.session_state.youtube_repository),
                        kwargs={'keyword_limit': keyword_limit}
                    )
                    thread.daemon = True
                    thread.start()
                    set_crawler_running(True)
                    st.session_state.jump_to_logs = True
                    st.session_state.auto_refresh_enabled = True
                    time.sleep(0.5)
                    st.rerun()
    
    with col2:
        st.subheader("ğŸŒ æ‰©æ•£å‘ç°ä»»åŠ¡")
        st.write("ä»å·²æœ‰KOLçš„æ¨èåˆ—è¡¨ä¸­å‘ç°æ–°KOL")
        
        stats = get_statistics('youtube')
        st.info(f"å½“å‰å¾…æ‰©æ•£é˜Ÿåˆ—: {stats.get('pending_expansions', 0)} ä¸ªKOL")
        
        if stats.get('pending_expansions', 0) == 0:
            st.warning("æ‰©æ•£é˜Ÿåˆ—ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œåˆå§‹å‘ç°ä»»åŠ¡")
        
        if st.button("â–¶ï¸ å¼€å§‹æ‰©æ•£å‘ç°", disabled=running or stats.get('pending_expansions', 0) == 0, key="start_youtube_expand"):
                if not st.session_state.youtube_repository:
                    st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
                else:
                    clear_logs()
                    add_log("=" * 60, "INFO")
                    add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - YouTubeæ‰©æ•£å‘ç°", "INFO")
                    add_log("=" * 60, "INFO")
                    add_log("ç”¨æˆ·å¯åŠ¨æ‰©æ•£å‘ç°ä»»åŠ¡", "INFO")
                    
                    thread = threading.Thread(
                        target=run_youtube_crawler_task,
                        args=("expand", st.session_state.youtube_repository)
                    )
                    thread.daemon = True
                    thread.start()
                    set_crawler_running(True)
                    st.session_state.jump_to_logs = True
                    st.session_state.auto_refresh_enabled = True
                    time.sleep(0.5)
                    st.rerun()
    
    st.divider()
    
    with st.expander("âš™ï¸ é«˜çº§é…ç½®", expanded=False):
        st.subheader("çˆ¬è™«å‚æ•°è®¾ç½®")
        col1, col2 = st.columns(2)
        with col1:
            ai_threshold = st.slider("AIå†…å®¹å æ¯”é˜ˆå€¼", min_value=0.1, max_value=0.9, value=0.3, step=0.05, format="%.0f%%")
            sample_videos = st.number_input("æ¯ä¸ªé¢‘é“åˆ†æè§†é¢‘æ•°", min_value=5, max_value=50, value=10, step=5)
        with col2:
            rate_limit = st.number_input("è¯·æ±‚é—´éš”(ç§’)", min_value=1, max_value=10, value=2, step=1)
            max_kols = st.number_input("æœ€å¤§KOLæ•°é‡", min_value=100, max_value=10000, value=1000, step=100)
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            st.success("é…ç½®å·²ä¿å­˜ï¼")

def render_github_crawler():
    """æ¸²æŸ“GitHubçˆ¬è™«æ§åˆ¶"""
    st.markdown('<div class="main-header">ğŸš€ GitHub çˆ¬è™«æ§åˆ¶</div>', unsafe_allow_html=True)
    
    running = is_crawler_running()
    if running:
        st.warning("âš ï¸ çˆ¬è™«æ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        st.info("ğŸ’¡ åˆ‡æ¢åˆ°ã€ŒğŸ“ æ—¥å¿—æŸ¥çœ‹ã€é¡µé¢æŸ¥çœ‹å®æ—¶è¿›åº¦")
        if st.button("â¹ï¸ æ ‡è®°ä¸ºå·²å®Œæˆ", key="mark_complete_github"):
            set_crawler_running(False)
            st.rerun()
    else:
        st.success("âœ… çˆ¬è™«ç©ºé—²ï¼Œå¯ä»¥å¯åŠ¨æ–°ä»»åŠ¡")
    
    st.divider()
    
    st.subheader("ğŸ” GitHubå¼€å‘è€…å‘ç°")
    st.write("ä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼ˆæ— APIé™åˆ¶ï¼‰æœç´¢GitHubï¼Œå‘ç°ç‹¬ç«‹AIå¼€å‘è€…")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        max_developers = st.slider(
            "æœ€å¤§çˆ¬å–å¼€å‘è€…æ•°é‡",
            min_value=1,
            max_value=400,
            value=50,
            step=1,
            help="é™åˆ¶æœ¬æ¬¡ä»»åŠ¡æœ€å¤šçˆ¬å–çš„å¼€å‘è€…æ•°é‡"
        )
    
    with col2:
        strategy = st.selectbox(
            "æœç´¢ç­–ç•¥",
            ["quality_projects", "comprehensive", "keywords", "topics", "awesome", "explore", "indie"],
            index=0,
            format_func=lambda x: {
                "quality_projects": "ğŸ¯ ä¼˜è´¨é¡¹ç›®è´¡çŒ®è€…ï¼ˆæ¨èï¼‰",
                "comprehensive": "ğŸ“¦ ç»¼åˆç­–ç•¥",
                "keywords": "ğŸ”‘ ä»…å…³é”®è¯",
                "topics": "ğŸ·ï¸ ä»…Topics",
                "awesome": "â­ ä»…Awesomeåˆ—è¡¨",
                "explore": "ğŸ”­ ä»…Explore",
                "indie": "ğŸ‘¤ ä»…ç‹¬ç«‹å¼€å‘è€…"
            }[x],
            help="ä¼˜è´¨é¡¹ç›®ç­–ç•¥ï¼šä»Stable Diffusionã€ComfyUIç­‰ä¼˜è´¨AIé¡¹ç›®ä¸­æ‰¾è´¡çŒ®è€…ï¼ˆæœ€ç²¾å‡†ï¼‰"
        )
    
    # ç­–ç•¥è¯´æ˜
    strategy_info = {
        "quality_projects": "ä»Stable Diffusionã€ComfyUIç­‰ä¼˜è´¨AIé¡¹ç›®ï¼ˆ100+ starsï¼‰ä¸­æ‰¾è´¡çŒ®è€…ï¼Œç­›é€‰æœ‰å½±å“åŠ›çš„å¼€å‘è€…ï¼ˆæœ€ç²¾å‡†ï¼Œæ¨èï¼‰",
        "comprehensive": "æ™ºèƒ½ç»„åˆå¤šç§ç­–ç•¥ï¼Œå°æ•°é‡æ—¶åªç”¨æœ€å¿«çš„æ–¹æ³•ï¼Œå¤§æ•°é‡æ—¶å…¨ç­–ç•¥è¦†ç›–",
        "keywords": "é€šè¿‡AIç›¸å…³å…³é”®è¯æœç´¢ä»“åº“ï¼Œæå–ownerï¼ˆå¿«é€Ÿï¼Œé€‚åˆå°æ•°é‡ï¼‰",
        "topics": "é€šè¿‡GitHub Topicsæ ‡ç­¾æœç´¢ï¼ˆä¸­ç­‰é€Ÿåº¦ï¼Œè´¨é‡è¾ƒé«˜ï¼‰",
        "awesome": "ä»Awesomeåˆ—è¡¨æå–è´¡çŒ®è€…ï¼ˆæ…¢ä½†è´¨é‡é«˜ï¼‰",
        "explore": "æœç´¢trendingé¡¹ç›®ï¼ˆè¦†ç›–é¢å¹¿ï¼‰",
        "indie": "ä¸“é—¨æœç´¢ç‹¬ç«‹å¼€å‘è€…å…³é”®è¯ï¼ˆç²¾å‡†ä½†æ•°é‡å°‘ï¼‰"
    }
    
    st.info(f"ğŸ’¡ {strategy_info[strategy]}")
    
    # é¢„ä¼°æ—¶é—´
    if max_developers <= 10:
        estimated_time = "çº¦1-2åˆ†é’Ÿ"
    elif max_developers <= 50:
        estimated_time = "çº¦3-5åˆ†é’Ÿ"
    elif max_developers <= 100:
        estimated_time = "çº¦8-12åˆ†é’Ÿ"
    else:
        estimated_time = "çº¦15-25åˆ†é’Ÿ"
    
    st.caption(f"â±ï¸ é¢„è®¡è€—æ—¶ï¼š{estimated_time}ï¼ˆä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼Œæ— APIé™åˆ¶ï¼‰")
    
    if st.button("â–¶ï¸ å¼€å§‹GitHubå‘ç°", disabled=running, key="start_github_discovery"):
        if not st.session_state.github_repository:
            st.error("æ•°æ®åº“æœªè¿æ¥ï¼Œæ— æ³•å¯åŠ¨ä»»åŠ¡")
        else:
            clear_logs()
            add_log("=" * 60, "INFO")
            add_log("å¼€å§‹æ–°çš„çˆ¬è™«ä»»åŠ¡ - GitHubå¼€å‘è€…å‘ç°", "INFO")
            add_log("=" * 60, "INFO")
            add_log(f"ç”¨æˆ·å¯åŠ¨GitHubå‘ç°ä»»åŠ¡", "INFO")
            add_log(f"  - æœ€å¤§æ•°é‡: {max_developers}", "INFO")
            add_log(f"  - æœç´¢ç­–ç•¥: {strategy}", "INFO")
            add_log(f"  - ä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼ˆæ— APIé™åˆ¶ï¼‰", "INFO")
            
            thread = threading.Thread(
                target=run_github_crawler_task,
                args=("discovery", st.session_state.github_repository),
                kwargs={"max_developers": max_developers, "strategy": strategy}
            )
            thread.daemon = True
            thread.start()
            set_crawler_running(True)
            st.session_state.jump_to_logs = True
            st.session_state.auto_refresh_enabled = True
            time.sleep(0.5)
            st.rerun()

def render_data_browser():
    """æ¸²æŸ“ç»Ÿä¸€çš„æ•°æ®æµè§ˆé¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“‹ æ•°æ®æµè§ˆ</div>', unsafe_allow_html=True)
    
    # åˆå§‹åŒ–å¹³å°é€‰æ‹©
    if 'data_browser_platform' not in st.session_state:
        st.session_state.data_browser_platform = "YouTube"
    
    # å¹³å°é€‰æ‹© - ä½¿ç”¨æŒ‰é’®ç»„
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ¥ YouTube", key="btn_yt_data", use_container_width=True, 
                    type="primary" if st.session_state.data_browser_platform == "YouTube" else "secondary"):
            st.session_state.data_browser_platform = "YouTube"
            st.rerun()
    with col2:
        if st.button("ğŸ’» GitHub", key="btn_gh_data", use_container_width=True,
                    type="primary" if st.session_state.data_browser_platform == "GitHub" else "secondary"):
            st.session_state.data_browser_platform = "GitHub"
            st.rerun()
    
    st.divider()
    
    if st.session_state.data_browser_platform == "YouTube":
        render_youtube_data_content()
    else:
        render_github_data_content()

def render_youtube_data_content():
    """æ¸²æŸ“YouTubeæ•°æ®å†…å®¹"""
    if not st.session_state.youtube_repository:
        st.warning("è¯·å…ˆè¿æ¥æ•°æ®åº“")
        return
    
    col1, col2, col3 = st.columns(3)
    with col1:
        status_filter = st.selectbox("çŠ¶æ€ç­›é€‰", ["å…¨éƒ¨", "åˆæ ¼", "å¾…åˆ†æ", "å·²æ‹’ç»"], index=1, key="yt_status")
    with col2:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["AIå æ¯”", "è®¢é˜…æ•°", "å¹³å‡è§‚çœ‹", "çˆ¬å–æ—¶é—´"], index=0, key="yt_sort")
    with col3:
        limit = st.number_input("æ˜¾ç¤ºæ•°é‡", min_value=10, max_value=1000, value=50, step=10, key="yt_limit")
    
    status_map = {"å…¨éƒ¨": None, "åˆæ ¼": "qualified", "å¾…åˆ†æ": "pending", "å·²æ‹’ç»": "rejected"}
    sort_map = {"AIå æ¯”": "ai_ratio DESC", "è®¢é˜…æ•°": "subscribers DESC", "å¹³å‡è§‚çœ‹": "avg_views DESC", "çˆ¬å–æ—¶é—´": "discovered_at DESC"}
    
    query = "SELECT * FROM youtube_kols"
    if status_filter != "å…¨éƒ¨":
        query += f" WHERE status = '{status_map[status_filter]}'"
    query += f" ORDER BY {sort_map[sort_by]} LIMIT {limit}"
    
    kols = st.session_state.db.fetchall(query)
    
    if kols:
        df = pd.DataFrame(kols)
        display_columns = ['channel_name', 'channel_url', 'subscribers', 'total_videos', 'ai_ratio',
                         'avg_views', 'avg_likes', 'avg_comments', 'engagement_rate', 'contact_info', 'status', 'discovered_at']
        display_df = df[display_columns].copy()
        display_df.columns = ['é¢‘é“åç§°', 'é¢‘é“é“¾æ¥', 'è®¢é˜…æ•°', 'æ€»è§†é¢‘', 'AIå æ¯”', 'å¹³å‡è§‚çœ‹', 'å¹³å‡ç‚¹èµ', 'å¹³å‡è¯„è®º', 'äº’åŠ¨ç‡', 'è”ç³»æ–¹å¼', 'çŠ¶æ€', 'çˆ¬å–æ—¶é—´']
        
        display_df['æ€»è§†é¢‘'] = display_df['æ€»è§†é¢‘'].apply(lambda x: str(int(x)))
        display_df['AIå æ¯”'] = display_df['AIå æ¯”'].apply(lambda x: f"{x*100:.1f}%")
        display_df['äº’åŠ¨ç‡'] = display_df['äº’åŠ¨ç‡'].apply(lambda x: f"{x:.2f}%")
        display_df['è®¢é˜…æ•°'] = display_df['è®¢é˜…æ•°'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡è§‚çœ‹'] = display_df['å¹³å‡è§‚çœ‹'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡ç‚¹èµ'] = display_df['å¹³å‡ç‚¹èµ'].apply(lambda x: f"{x:,}")
        display_df['å¹³å‡è¯„è®º'] = display_df['å¹³å‡è¯„è®º'].apply(lambda x: f"{x:,}")
        display_df['è”ç³»æ–¹å¼'] = display_df['è”ç³»æ–¹å¼'].fillna('')
        
        def format_time(dt):
            if pd.isna(dt):
                return ""
            if isinstance(dt, str):
                dt = pd.to_datetime(dt)
            dt_beijing = dt + pd.Timedelta(hours=8)
            return dt_beijing.strftime('%Y-%m-%d %H:%M:%S')
        
        display_df['çˆ¬å–æ—¶é—´'] = display_df['çˆ¬å–æ—¶é—´'].apply(format_time)
        
        table_height = min(max(len(display_df) * 35 + 50, 200), 800)
        st.dataframe(display_df, width='stretch', hide_index=True, height=table_height,
                    column_config={"é¢‘é“é“¾æ¥": st.column_config.LinkColumn("é¢‘é“é“¾æ¥", help="ç‚¹å‡»æ‰“å¼€YouTubeé¢‘é“")})
        
        st.divider()
        
        # å¯¼å‡ºæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“¥ å¯¼å‡ºExcel", key="export_yt_excel", use_container_width=True):
                from tasks.youtube.export import YouTubeExportTask
                export_task = YouTubeExportTask(st.session_state.youtube_repository)
                filepath = export_task.run()
                if filepath:
                    add_log(f"å¯¼å‡ºExcel: {filepath}", "SUCCESS")
        with col2:
            csv = display_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSV", 
                data=csv,
                file_name=f"youtube_kol_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    else:
        st.info("ğŸ“­ æš‚æ— æ•°æ®")

def render_github_data_content():
    """æ¸²æŸ“GitHubæ•°æ®å†…å®¹"""
    if not st.session_state.github_repository:
        st.warning("è¯·å…ˆè¿æ¥æ•°æ®åº“")
        return
    
    col1, col2, col3 = st.columns(3)
    with col1:
        status_filter = st.selectbox("çŠ¶æ€ç­›é€‰", ["å…¨éƒ¨", "åˆæ ¼", "å¾…åˆ†æ", "å·²æ‹’ç»"], index=1, key="gh_status")
    with col2:
        sort_by = st.selectbox("æ’åºæ–¹å¼", ["æ€»Stars", "Followers", "ä»“åº“æ•°", "å‘ç°æ—¶é—´"], index=0, key="gh_sort")
    with col3:
        limit = st.number_input("æ˜¾ç¤ºæ•°é‡", min_value=10, max_value=1000, value=50, step=10, key="gh_limit")
    
    status_map = {"å…¨éƒ¨": None, "åˆæ ¼": "qualified", "å¾…åˆ†æ": "pending", "å·²æ‹’ç»": "rejected"}
    sort_map = {"æ€»Stars": "total_stars DESC", "Followers": "followers DESC", "ä»“åº“æ•°": "public_repos DESC", "å‘ç°æ—¶é—´": "discovered_at DESC"}
    
    query = "SELECT * FROM github_developers"
    if status_filter != "å…¨éƒ¨":
        query += f" WHERE status = '{status_map[status_filter]}'"
    query += f" ORDER BY {sort_map[sort_by]} LIMIT {limit}"
    
    devs = st.session_state.db.fetchall(query)
    
    if devs:
        df = pd.DataFrame(devs)
        display_columns = ['username', 'name', 'profile_url', 'followers', 'public_repos', 'total_stars', 'contact_info', 'status', 'discovered_at']
        display_df = df[display_columns].copy()
        display_df.columns = ['ç”¨æˆ·å', 'å§“å', 'ä¸»é¡µé“¾æ¥', 'Followers', 'ä»“åº“æ•°', 'æ€»Stars', 'è”ç³»æ–¹å¼', 'çŠ¶æ€', 'å‘ç°æ—¶é—´']
        
        display_df['Followers'] = display_df['Followers'].apply(lambda x: f"{x:,}")
        display_df['ä»“åº“æ•°'] = display_df['ä»“åº“æ•°'].apply(lambda x: f"{x:,}")
        display_df['æ€»Stars'] = display_df['æ€»Stars'].apply(lambda x: f"{x:,}")
        display_df['è”ç³»æ–¹å¼'] = display_df['è”ç³»æ–¹å¼'].fillna('')
        
        table_height = min(max(len(display_df) * 35 + 50, 200), 800)
        st.dataframe(display_df, width='stretch', hide_index=True, height=table_height,
                    column_config={"ä¸»é¡µé“¾æ¥": st.column_config.LinkColumn("ä¸»é¡µé“¾æ¥", help="ç‚¹å‡»æ‰“å¼€GitHubä¸»é¡µ")})
        
        st.divider()
        
        # å¯¼å‡ºæŒ‰é’®
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“¥ å¯¼å‡ºExcel", key="export_gh_excel", use_container_width=True):
                from tasks.github.export import GitHubExportTask
                export_task = GitHubExportTask(st.session_state.github_repository)
                filepath = export_task.run()
                if filepath:
                    add_log(f"å¯¼å‡ºExcel: {filepath}", "SUCCESS")
        with col2:
            csv = display_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSV", 
                data=csv,
                file_name=f"github_devs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    else:
        st.info("ğŸ“­ æš‚æ— æ•°æ®")

def render_logs():
    """æ¸²æŸ“æ—¥å¿—æŸ¥çœ‹é¡µé¢"""
    st.markdown('<div class="main-header">ğŸ“ å®æ—¶æ—¥å¿—</div>', unsafe_allow_html=True)
    
    if 'auto_refresh_enabled' not in st.session_state:
        st.session_state.auto_refresh_enabled = True
    
    crawler_is_running = is_crawler_running()
    
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("ğŸ”„ åˆ·æ–°æ—¥å¿—", key="refresh_logs_btn"):
            st.rerun()
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—", key="clear_logs_btn"):
            if clear_logs():
                st.success("âœ… æ—¥å¿—å·²æ¸…ç©º")
                time.sleep(0.5)
                st.rerun()
            else:
                st.error("âŒ æ¸…ç©ºæ—¥å¿—å¤±è´¥")
    with col3:
        auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (æ¯3ç§’)", value=st.session_state.auto_refresh_enabled,
                                   key="auto_refresh_checkbox_unique", help="çˆ¬è™«è¿è¡Œæ—¶è‡ªåŠ¨åˆ·æ–°æ—¥å¿—")
        if auto_refresh != st.session_state.auto_refresh_enabled:
            st.session_state.auto_refresh_enabled = auto_refresh
    
    st.divider()
    
    log_file = os.path.join(LOG_DIR, f"{datetime.now().strftime('%Y%m%d')}.log")
    all_logs = []
    
    if os.path.exists(log_file):
        try:
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            for encoding in encodings:
                try:
                    with open(log_file, 'r', encoding=encoding) as f:
                        file_logs = f.readlines()
                        all_logs = [line.strip() for line in file_logs if line.strip()]
                    break
                except UnicodeDecodeError:
                    continue
        except Exception as e:
            st.error(f"è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
    
    log_count = len(all_logs)
    display_count = min(log_count, 200)
    
    if crawler_is_running:
        st.markdown(f"""
        <div style="background: linear-gradient(90deg, #1e3a8a 0%, #3b82f6 100%); 
                    padding: 15px; border-radius: 10px; margin-bottom: 10px;">
            <div style="display: flex; align-items: center; justify-content: space-between;">
                <div style="display: flex; align-items: center;">
                    <div style="width: 12px; height: 12px; background: #22c55e; 
                                border-radius: 50%; margin-right: 10px;"></div>
                    <span style="color: white; font-size: 18px; font-weight: bold;">
                        ğŸ”„ çˆ¬è™«è¿è¡Œä¸­...
                    </span>
                </div>
                <span style="color: #e0e7ff; font-size: 14px;">
                    å…± {log_count} æ¡æ—¥å¿— | æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡
                </span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div style="background: linear-gradient(90deg, #065f46 0%, #10b981 100%); 
                    padding: 15px; border-radius: 10px; margin-bottom: 10px;">
            <div style="display: flex; align-items: center; justify-content: space-between;">
                <div style="display: flex; align-items: center;">
                    <span style="color: white; font-size: 18px; font-weight: bold;">
                        âœ… çˆ¬è™«å·²åœæ­¢
                    </span>
                </div>
                <span style="color: #d1fae5; font-size: 14px;">
                    å…± {log_count} æ¡æ—¥å¿— | æ˜¾ç¤ºæœ€è¿‘ {display_count} æ¡
                </span>
            </div>
        </div>
        """, unsafe_allow_html=True)
    
    if all_logs:
        logs_text = "\n".join(all_logs[-200:])
        
        st.markdown("""
        <style>
        .log-container {
            background-color: #1e1e1e;
            color: #d4d4d4;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 13px;
            padding: 15px;
            border-radius: 5px;
            height: 500px;
            overflow-y: auto;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .log-container::-webkit-scrollbar {
            width: 10px;
        }
        .log-container::-webkit-scrollbar-track {
            background: #2d2d2d;
        }
        .log-container::-webkit-scrollbar-thumb {
            background: #555;
            border-radius: 5px;
        }
        .log-container::-webkit-scrollbar-thumb:hover {
            background: #777;
        }
        </style>
        """, unsafe_allow_html=True)
        
        log_container_id = f"log_container_{int(time.time() * 1000)}"
        import html
        logs_html = html.escape(logs_text)
        
        st.markdown(f'<div class="log-container" id="{log_container_id}">{logs_html}</div>', unsafe_allow_html=True)
        
        st.markdown(f"""
        <script>
        setTimeout(function() {{
            var container = document.getElementById('{log_container_id}');
            if (container) {{
                container.scrollTop = container.scrollHeight;
            }}
        }}, 100);
        </script>
        """, unsafe_allow_html=True)
    else:
        st.info("æš‚æ— æ—¥å¿—è®°å½•")
    
    if st.session_state.auto_refresh_enabled and crawler_is_running:
        time.sleep(3)
        st.rerun()

def render_ai_rules():
    """æ¸²æŸ“AIè§„åˆ™é…ç½®é¡µé¢ - ä»…é€‚ç”¨äºYouTube"""
    st.markdown('<div class="main-header">ğŸ¯ AIè¿‡æ»¤è§„åˆ™é…ç½®</div>', unsafe_allow_html=True)
    
    st.info("ğŸ’¡ é…ç½®AIå†…å®¹è¯†åˆ«è§„åˆ™ï¼Œè°ƒæ•´å…³é”®è¯å’Œç­›é€‰æ¡ä»¶ï¼ˆä»…é€‚ç”¨äºYouTubeå¹³å°ï¼‰")
    
    config_path = os.path.join(PROJECT_ROOT, 'config', 'config.json')
    config_example_path = os.path.join(PROJECT_ROOT, 'config', 'config.example.json')
    
    if not os.path.exists(config_path):
        if os.path.exists(config_example_path):
            import shutil
            os.makedirs(os.path.dirname(config_path), exist_ok=True)
            shutil.copy(config_example_path, config_path)
            st.success("âœ… å·²è‡ªåŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶")
        else:
            st.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¸”æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶ config/config.example.json")
            return
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        st.error(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    st.subheader("ğŸ“Š åŸºç¡€ç­›é€‰å‚æ•°")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**AIå†…å®¹å æ¯”é˜ˆå€¼**")
        ai_ratio_percentage = st.slider("AIå æ¯”", min_value=0, max_value=100,
                                       value=int(config['crawler']['ai_ratio_threshold'] * 100),
                                       step=5, format="%d%%",
                                       help="åªæœ‰AIå†…å®¹å æ¯”è¶…è¿‡æ­¤é˜ˆå€¼çš„é¢‘é“æ‰ä¼šè¢«æ ‡è®°ä¸ºåˆæ ¼",
                                       label_visibility="collapsed")
        ai_ratio_threshold = ai_ratio_percentage / 100.0
    
    with col2:
        sample_video_count = st.number_input("æ¯ä¸ªé¢‘é“åˆ†æè§†é¢‘æ•°", min_value=5, max_value=50,
                                            value=config['crawler']['sample_video_count'], step=5,
                                            help="åˆ†ææ¯ä¸ªé¢‘é“æ—¶æŠ“å–çš„è§†é¢‘æ•°é‡ï¼Œè¶Šå¤šè¶Šå‡†ç¡®ä½†è¶Šæ…¢")
    
    with col3:
        active_days_threshold = st.number_input("æ´»è·ƒåº¦é˜ˆå€¼(å¤©)", min_value=30, max_value=365,
                                               value=config['crawler']['active_days_threshold'], step=30,
                                               help="æœ€åä¸€æ¬¡å‘å¸ƒè§†é¢‘è·ä»Šçš„å¤©æ•°ï¼Œè¶…è¿‡æ­¤å€¼è§†ä¸ºä¸æ´»è·ƒ")
    
    st.divider()
    
    st.subheader("ğŸ”‘ AIå…³é”®è¯åº“")
    st.markdown("""
    **å…³é”®è¯åŒ¹é…è§„åˆ™**ï¼š
    - âœ… **ä¸åŒºåˆ†å¤§å°å†™**ï¼š'AI' å’Œ 'ai' æ•ˆæœç›¸åŒ
    - âœ… **éƒ¨åˆ†åŒ¹é…**ï¼š'AI' å¯ä»¥åŒ¹é… 'AI video'ã€'using AI' ç­‰
    - âœ… **åŒé‡æ£€æŸ¥**ï¼šåŒæ—¶æ£€æŸ¥è§†é¢‘æ ‡é¢˜å’Œæè¿°
    - âœ… **å®½æ¾åŒ¹é…**ï¼šåªè¦åŒ¹é…ä»»æ„ä¸€ä¸ªå…³é”®è¯å°±åˆ¤å®šä¸ºAIç›¸å…³
    - âœ… **ä¼˜å…ˆçº§è¯´æ˜**ï¼šé«˜/ä¸­/ä½ä¼˜å…ˆçº§ä»…ç”¨äºç»„ç»‡ç®¡ç†ï¼ŒåŒ¹é…æƒé‡ç›¸åŒ
    """)
    
    tab1, tab2, tab3 = st.tabs(["ğŸ”¥ é«˜ä¼˜å…ˆçº§", "â­ ä¸­ä¼˜å…ˆçº§", "ğŸ“Œ ä½ä¼˜å…ˆçº§"])
    
    with tab1:
        st.caption("ğŸ’¡ æœ€æ–°AIå·¥å…·å’Œçƒ­é—¨è¯é¢˜ï¼ˆå¦‚ï¼šSora, Kling, Runwayç­‰ï¼‰")
        high_keywords = st.text_area("é«˜ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                                    value="\n".join(config['keywords']['priority_high']),
                                    height=200, help="è¾“å…¥æœ€æ–°ã€æœ€çƒ­é—¨çš„AIå·¥å…·åç§°")
        newline = '\n'
        st.caption(f"âœ… å½“å‰æ•°é‡: {len([k for k in high_keywords.split(newline) if k.strip()])} ä¸ª")
    
    with tab2:
        st.caption("ğŸ’¡ ä¸»æµAIå·¥å…·å’Œå¸¸è§æœ¯è¯­ï¼ˆå¦‚ï¼šChatGPT, Midjourney, Claudeç­‰ï¼‰")
        medium_keywords = st.text_area("ä¸­ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                                      value="\n".join(config['keywords']['priority_medium']),
                                      height=200, help="è¾“å…¥ä¸»æµã€å¸¸ç”¨çš„AIå·¥å…·å’Œæœ¯è¯­")
        st.caption(f"âœ… å½“å‰æ•°é‡: {len([k for k in medium_keywords.split(newline) if k.strip()])} ä¸ª")
    
    with tab3:
        st.caption("ğŸ’¡ æŠ€æœ¯æœ¯è¯­å’Œä¸“ä¸šè¯æ±‡ï¼ˆå¦‚ï¼šLLM, Diffusion Model, AI workflowç­‰ï¼‰")
        low_keywords = st.text_area("ä½ä¼˜å…ˆçº§å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                                   value="\n".join(config['keywords']['priority_low']),
                                   height=200, help="è¾“å…¥æŠ€æœ¯æ€§è¾ƒå¼ºçš„ä¸“ä¸šæœ¯è¯­")
        st.caption(f"âœ… å½“å‰æ•°é‡: {len([k for k in low_keywords.split(newline) if k.strip()])} ä¸ª")
    
    st.divider()
    
    st.subheader("ğŸš« æ’é™¤è§„åˆ™")
    st.markdown("""
    **æ’é™¤è§„åˆ™è¯´æ˜**ï¼š
    - âš ï¸ **åŒ¹é…æ–¹å¼**ï¼šé¢‘é“åç§°æˆ–è§†é¢‘æ ‡é¢˜ä¸­åŒ…å«è¿™äº›å…³é”®è¯å°†è¢«è‡ªåŠ¨æ’é™¤
    - ğŸ’¡ **å¸¸è§ç±»å‹**ï¼šè¯¾ç¨‹/æ•™å­¦ï¼ˆè¯¾ã€è®²ã€è¯¾ï¼‰ã€å­¦æœ¯æœºæ„ï¼ˆå¤§å­¦ã€ç ”ç©¶æ‰€ï¼‰ã€æ–°é—»åª’ä½“ï¼ˆnewsã€æ–°é—»ï¼‰ç­‰
    - âœï¸ **å®Œå…¨è‡ªå®šä¹‰**ï¼šä½ å¯ä»¥æ·»åŠ ä»»ä½•æƒ³è¦æ’é™¤çš„å…³é”®è¯ï¼Œä¸é™äºä¸Šè¿°åˆ†ç±»
    - ğŸ¯ **ç›®çš„**ï¼šè¿‡æ»¤æ‰éç›®æ ‡KOLï¼Œèšç„¦äºAIå†…å®¹åˆ›ä½œè€…
    """)
    
    all_exclusion_keywords = []
    all_exclusion_keywords.extend(config['exclusion_rules'].get('course_keywords', []))
    all_exclusion_keywords.extend(config['exclusion_rules'].get('academic_keywords', []))
    all_exclusion_keywords.extend(config['exclusion_rules'].get('news_keywords', []))
    
    exclusion_keywords = st.text_area("æ’é™¤å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", value="\n".join(all_exclusion_keywords),
                                     height=300, help="è¾“å…¥ä»»ä½•ä½ æƒ³æ’é™¤çš„å…³é”®è¯ï¼Œå¦‚ï¼šè¯¾ç¨‹ã€å¤§å­¦ã€æ–°é—»ã€tutorialã€universityç­‰")
    
    keyword_count = len([k for k in exclusion_keywords.split(newline) if k.strip()])
    st.caption(f"âœ… å½“å‰å…± {keyword_count} ä¸ªæ’é™¤å…³é”®è¯")
    
    with st.expander("ğŸ’¡ å¸¸ç”¨æ’é™¤å…³é”®è¯å‚è€ƒ", expanded=False):
        st.markdown("""
        **è¯¾ç¨‹/æ•™å­¦ç±»**ï¼šè¯¾ã€è®²ã€è¯¾ã€lessonã€lectureã€tutorialã€æ•™ç¨‹ã€æ•™å­¦ã€ç³»åˆ—è¯¾
        
        **å­¦æœ¯æœºæ„ç±»**ï¼šuniversityã€å¤§å­¦ã€collegeã€å­¦é™¢ã€instituteã€ç ”ç©¶æ‰€ã€å®éªŒå®¤
        
        **æ–°é—»åª’ä½“ç±»**ï¼šnewsã€æ–°é—»ã€mediaã€åª’ä½“ã€æŠ¥å¯¼ã€æŠ¥é“ã€é¢‘é“
        
        **å…¶ä»–ç±»å‹**ï¼šä½ å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚æ·»åŠ ä»»ä½•å…³é”®è¯
        """)
    
    st.divider()
    
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
            config['crawler']['ai_ratio_threshold'] = ai_ratio_threshold
            config['crawler']['sample_video_count'] = sample_video_count
            config['crawler']['active_days_threshold'] = active_days_threshold
            
            config['keywords']['priority_high'] = [k.strip() for k in high_keywords.split(newline) if k.strip()]
            config['keywords']['priority_medium'] = [k.strip() for k in medium_keywords.split(newline) if k.strip()]
            config['keywords']['priority_low'] = [k.strip() for k in low_keywords.split(newline) if k.strip()]
            
            exclusion_list = [k.strip() for k in exclusion_keywords.split(newline) if k.strip()]
            config['exclusion_rules']['course_keywords'] = exclusion_list
            config['exclusion_rules']['academic_keywords'] = []
            config['exclusion_rules']['news_keywords'] = []
            
            try:
                config_path = os.path.join(PROJECT_ROOT, 'config', 'config.json')
                os.makedirs(os.path.dirname(config_path), exist_ok=True)
                with open(config_path, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                st.success("âœ… é…ç½®å·²ä¿å­˜ï¼æ–°é…ç½®å°†åœ¨ä¸‹æ¬¡çˆ¬è™«ä»»åŠ¡æ—¶ç”Ÿæ•ˆ")
                add_log("AIè§„åˆ™é…ç½®å·²æ›´æ–°", "INFO")
            except Exception as e:
                st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    
    with col2:
        if st.button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤", use_container_width=True):
            st.warning("âš ï¸ æ­¤æ“ä½œå°†æ¢å¤é»˜è®¤é…ç½®ï¼Œç¡®å®šè¦ç»§ç»­å—ï¼Ÿ")
            if st.button("ç¡®è®¤é‡ç½®"):
                st.info("è¯·æ‰‹åŠ¨ç¼–è¾‘ config/config.json æ–‡ä»¶æ¢å¤é»˜è®¤å€¼")
    
    st.divider()
    st.subheader("ğŸ“‹ å½“å‰é…ç½®æ‘˜è¦")
    
    summary_col1, summary_col2, summary_col3 = st.columns(3)
    with summary_col1:
        st.metric("AIå æ¯”é˜ˆå€¼", f"{ai_ratio_threshold*100:.0f}%")
        st.metric("åˆ†æè§†é¢‘æ•°", f"{sample_video_count} ä¸ª")
    with summary_col2:
        total_keywords = len([k for k in high_keywords.split(newline) if k.strip()]) + \
                        len([k for k in medium_keywords.split(newline) if k.strip()]) + \
                        len([k for k in low_keywords.split(newline) if k.strip()])
        st.metric("æ€»å…³é”®è¯æ•°", f"{total_keywords} ä¸ª")
        st.metric("æ´»è·ƒåº¦é˜ˆå€¼", f"{active_days_threshold} å¤©")
    with summary_col3:
        total_exclusions = len([k for k in exclusion_keywords.split(newline) if k.strip()])
        st.metric("æ’é™¤è§„åˆ™æ•°", f"{total_exclusions} ä¸ª")

def render_settings():
    """æ¸²æŸ“è®¾ç½®é¡µé¢"""
    st.markdown('<div class="main-header">âš™ï¸ ç³»ç»Ÿè®¾ç½®</div>', unsafe_allow_html=True)
    
    st.subheader("ğŸ—„ï¸ æ•°æ®åº“é…ç½®")
    st.info("ğŸ’¡ å½“å‰ä½¿ç”¨SQLiteæ•°æ®åº“ï¼Œæ•°æ®ä¿å­˜åœ¨ data/ai_kol_crawler.db")
    
    config_path = os.path.join(PROJECT_ROOT, 'config', 'config.json')
    config_example_path = os.path.join(PROJECT_ROOT, 'config', 'config.example.json')
    
    if not os.path.exists(config_path):
        if os.path.exists(config_example_path):
            import shutil
            os.makedirs(os.path.dirname(config_path), exist_ok=True)
            shutil.copy(config_example_path, config_path)
            st.success("âœ… å·²è‡ªåŠ¨åˆ›å»ºé…ç½®æ–‡ä»¶")
        else:
            st.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¸”æœªæ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶ config/config.example.json")
            return
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        st.error(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    col1, col2 = st.columns(2)
    with col1:
        db_host = st.text_input("æ•°æ®åº“åœ°å€", value=config['database'].get('host', 'localhost'), disabled=True)
        db_port = st.number_input("ç«¯å£", value=config['database'].get('port', 5432), disabled=True)
    with col2:
        db_name = st.text_input("æ•°æ®åº“å", value=config['database'].get('database', 'ai_kol_crawler'), disabled=True)
        db_user = st.text_input("ç”¨æˆ·å", value=config['database'].get('user', 'postgres'), disabled=True)
    
    st.caption("ğŸ’¡ æç¤º: SQLiteæ•°æ®åº“æ— éœ€é…ç½®ï¼Œå¦‚éœ€ä½¿ç”¨PostgreSQLè¯·ä¿®æ”¹ config/config.json")
    
    st.divider()
    
    st.subheader("ğŸ“¤ å¯¼å‡ºè®¾ç½®")
    col1, col2 = st.columns(2)
    with col1:
        output_dir = st.text_input("å¯¼å‡ºç›®å½•", value=config['export']['output_dir'])
    with col2:
        sort_by = st.selectbox("é»˜è®¤æ’åº", ["ai_ratio", "subscribers", "avg_views"],
                              index=["ai_ratio", "subscribers", "avg_views"].index(config['export']['sort_by']))
    
    st.divider()
    
    st.subheader("ğŸ—‚ï¸ æ•°æ®åº“ç®¡ç†")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š æŸ¥çœ‹æ•°æ®åº“å¤§å°", use_container_width=True):
            db_path = 'data/ai_kol_crawler.db'
            if os.path.exists(db_path):
                size = os.path.getsize(db_path) / 1024 / 1024
                st.info(f"æ•°æ®åº“å¤§å°: {size:.2f} MB")
            else:
                st.warning("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
    
    with col2:
        if st.button("ğŸ’¾ å¤‡ä»½æ•°æ®åº“", use_container_width=True):
            import shutil
            try:
                backup_dir = "backups"
                os.makedirs(backup_dir, exist_ok=True)
                backup_name = f"{backup_dir}/backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
                shutil.copy('data/ai_kol_crawler.db', backup_name)
                st.success(f"âœ… å¤‡ä»½æˆåŠŸ: {backup_name}")
            except Exception as e:
                st.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
    
    with col3:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®åº“", use_container_width=True):
            st.warning("âš ï¸ æ­¤æ“ä½œå°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼Œæ— æ³•æ¢å¤ï¼")
            confirm = st.checkbox("æˆ‘ç¡®è®¤è¦æ¸…ç©ºæ•°æ®åº“")
            if confirm and st.button("ç¡®è®¤æ¸…ç©º"):
                try:
                    if st.session_state.db:
                        st.session_state.db.execute("DELETE FROM youtube_videos")
                        st.session_state.db.execute("DELETE FROM youtube_expansion_queue")
                        st.session_state.db.execute("DELETE FROM youtube_kols")
                        st.session_state.db.execute("DELETE FROM github_repositories")
                        st.session_state.db.execute("DELETE FROM github_developers")
                        st.success("âœ… æ•°æ®åº“å·²æ¸…ç©º")
                except Exception as e:
                    st.error(f"âŒ æ¸…ç©ºå¤±è´¥: {e}")
    
    st.divider()
    
    st.subheader("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ç‰ˆæœ¬ä¿¡æ¯**")
        st.write("- ç³»ç»Ÿç‰ˆæœ¬: v2.0 (å¤šå¹³å°)")
        st.write("- æ•°æ®åº“: SQLite")
        st.write("- Pythonç‰ˆæœ¬:", sys.version.split()[0])
    
    with col2:
        st.write("**ç»Ÿè®¡ä¿¡æ¯**")
        youtube_stats = get_statistics('youtube')
        github_stats = get_statistics('github')
        st.write(f"- YouTube KOLæ•°: {youtube_stats.get('qualified_kols', 0)}")
        st.write(f"- GitHubå¼€å‘è€…æ•°: {github_stats.get('qualified_developers', 0)}")
        st.write(f"- æ€»è§†é¢‘æ•°: {youtube_stats.get('total_videos', 0)}")

if __name__ == "__main__":
    """ä¸»ç¨‹åº"""
    init_session_state()
    
    with st.sidebar:
        st.markdown("### ğŸ¤– å¤šå¹³å°çˆ¬è™«")
        
        if connect_database():
            st.success("âœ… å·²è¿æ¥")
        else:
            st.error("âŒ æœªè¿æ¥")
        
        # å¿«é€Ÿç»Ÿè®¡ - æ›´ç´§å‡‘
        youtube_stats = get_statistics('youtube')
        github_stats = get_statistics('github')
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**ğŸ¥ YT**")
            st.markdown(f"<div class='stat-number'>{youtube_stats.get('qualified_kols', 0)}</div>", unsafe_allow_html=True)
        with col2:
            st.markdown("**ğŸ’» GH**")
            st.markdown(f"<div class='stat-number'>{github_stats.get('qualified_developers', 0)}</div>", unsafe_allow_html=True)
        
        st.divider()
        
        # æ•°æ®æµè§ˆï¼ˆæœ€å‰é¢ï¼‰
        is_active = st.session_state.current_page == "data_browser"
        if st.button(
            "ğŸ“Š æ•°æ®æµè§ˆ", 
            key="btn_data_browser", 
            use_container_width=True,
            type="primary" if is_active else "secondary"
        ):
            st.session_state.current_page = "data_browser"
            st.rerun()
        
        # YouTubeåˆ†ç±»
        st.markdown("### ğŸ¥ YouTube")
        youtube_pages = {
            "youtube_dashboard": "ğŸ“Š ä»ªè¡¨ç›˜",
            "youtube_crawler": "ğŸš€ çˆ¬è™«",
            "youtube_ai_rules": "ğŸ¯ è§„åˆ™"
        }
        
        for page_key, page_name in youtube_pages.items():
            is_active = st.session_state.current_page == page_key
            if st.button(
                page_name, 
                key=f"btn_{page_key}", 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_page = page_key
                st.rerun()
        
        # GitHubåˆ†ç±»
        st.markdown("### ğŸ’» GitHub")
        github_pages = {
            "github_dashboard": "ğŸ“Š ä»ªè¡¨ç›˜",
            "github_crawler": "ğŸš€ çˆ¬è™«"
        }
        
        for page_key, page_name in github_pages.items():
            is_active = st.session_state.current_page == page_key
            if st.button(
                page_name, 
                key=f"btn_{page_key}", 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_page = page_key
                st.rerun()
        
        st.divider()
        
        # æ—¥å¿—æŸ¥çœ‹å’Œè®¾ç½®ï¼ˆæœ€åé¢ï¼‰
        system_pages = {
            "logs": "ğŸ“ æ—¥å¿—æŸ¥çœ‹",
            "settings": "âš™ï¸ è®¾ç½®"
        }
        
        for page_key, page_name in system_pages.items():
            is_active = st.session_state.current_page == page_key
            if st.button(
                page_name, 
                key=f"btn_{page_key}", 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_page = page_key
                st.rerun()
        
        st.divider()
        
        if is_crawler_running():
            st.warning("âš™ï¸ çˆ¬è™«è¿è¡Œä¸­...")
        
        st.caption("å¤šå¹³å°çˆ¬è™«ç³»ç»Ÿ v2.0")
        st.caption("Â© 2026 All Rights Reserved")
    
    # å¤„ç†è·³è½¬åˆ°æ—¥å¿—
    if st.session_state.jump_to_logs:
        st.session_state.current_page = "logs"
        st.session_state.jump_to_logs = False
    
    # ä¸»å†…å®¹åŒº
    page = st.session_state.current_page
    
    if page == "youtube_dashboard":
        render_youtube_dashboard()
    elif page == "youtube_crawler":
        render_youtube_crawler()
    elif page == "youtube_ai_rules":
        render_ai_rules()
    elif page == "github_dashboard":
        render_github_dashboard()
    elif page == "github_crawler":
        render_github_crawler()
    elif page == "data_browser":
        render_data_browser()
    elif page == "logs":
        render_logs()
    elif page == "settings":
        render_settings()
    else:
        render_youtube_dashboard()
